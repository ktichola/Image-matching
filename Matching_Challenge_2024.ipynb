{
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 71885,
          "databundleVersionId": 8143495,
          "sourceType": "competition"
        },
        {
          "sourceId": 3414836,
          "sourceType": "datasetVersion",
          "datasetId": 2058261
        },
        {
          "sourceId": 5373920,
          "sourceType": "datasetVersion",
          "datasetId": 3117886
        },
        {
          "sourceId": 7884485,
          "sourceType": "datasetVersion",
          "datasetId": 4628051
        },
        {
          "sourceId": 170475544,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 170565695,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 174129945,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 3736,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 2663
        },
        {
          "sourceId": 3840,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 2742
        },
        {
          "sourceId": 3846,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 2747
        },
        {
          "sourceId": 4534,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 3326
        },
        {
          "sourceId": 17191,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 14317
        },
        {
          "sourceId": 17555,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 14611
        }
      ],
      "dockerImageVersionId": 30699,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 1103.714466,
      "end_time": "2024-05-01T06:58:45.406221",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-05-01T06:40:21.691755",
      "version": "2.5.0"
    },
    "colab": {
      "name": "Matching Challenge 2024",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ktichola/Image-matching/blob/main/Matching_Challenge_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'image-matching-challenge-2024:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F71885%2F8143495%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240514%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240514T073113Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Db2998dc19c6fea3724d4be6d9232bcfdddd44999cd765d25f2e615edf7d4caeeef74a953468334cfe3e47d0b047e91b4c25c0f5fc417911fde47f439ce54efeebe37c33fe5e4e6894506292423b9d9ce24f953ddf0b678f26b16ea8545d9907c87913a86d01f9423185399dcad35c97b4b119ffd9bec8bcd22130930fc612360680fa7e3b57890b8c7fc75db1a1dfaad0397b17f23216bb57cf90987c4c592430d5198606740885366394af916628fe7339906dbd22f4adef7797fd0655db6c920b1deadaf528a6aeebc70bc34b4cc55d0776d4ff5d17024d130781d048d535ff61a8d763e0d5f2ffec259d12acad398fac46dbfb3c5d75746ab57ff822dd796,super-glue-pretrained-network:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F2058261%2F3414836%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240514%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240514T073113Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Da77b428b2ca951b83717dcd4bddbc4bd53c944e1234fa6f2dcfca24f08bb7142659154488fd804dd0ac115f79033173cbca9fe0634ca94906408f0998b2b778c87022ae5557673528bfab40c640cd466d4d861f51bb92815a3d79773523988672abab2f8e88fc81fad41e8832a9c9a44c68c1308b16843579bf3e13eaed3b3e70a88b90af0f14ed6e81db02c2df4d32f5f336710a6f69156b67c3e26b67a34122d4872bf91e68021dcabe5a402ce34004876ffd868edd0ab8fb206aec3ba4534383c360ec1c9fef874df42867355706de7d329482e1848c77e6f701e378349d5c439192b290b56678699cddca198a89dc881ddf8120d9a42d67e6a0cae6a4c94,kornia-local-feature-weights:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F3117886%2F5373920%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240514%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240514T073113Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D0d55371cc9c16f96568c2947511ea01605c47e898a548e402548645a30e2db7887c5f975104b9c03ce3c9f303edb65e0a72dceb5a5e553662dae08158c2fea41a827f47f85b8efca891ccf2dc27d0cedb930e3b1a634545fd455f7261404bf19b6b88da918990bf86a789531c6494cc621159fa66d974e03cf951205b95cd66db5085c4ed9a45976fae8050226ef3f0292c8d80b1df4b73ca3875b5ca69ece879b4845847afed42572c75d1c9c39cd966543eb7791ffdc60be1ffebfa74262b6529e90d541065d76c0126afd523b185e675a0c02cdf16e233f942cdaf667592c1e253c6f2c281534e8a864e16695adc9e3aeb80a581fa6bbbb79b15e379e6b42,imc2024-packages-lightglue-rerun-kornia:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4628051%2F7884485%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240514%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240514T073113Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D479c163e47b18f08c212ad8f434d72bf0003711e1dc6a98edd6942f3b0e4b63fca9698df7e20e49f789dce4c9f7308ac1c6c1ac5d772c279472a7dfe9876e4db35b826afe72a204f44acf0cf2d0893038348659929133c999cdde920013919c9e53ddb9ff58bb710da7ec886556b3150e5b8f4322993ce41accb8d00e8d44a61f373c0e9ab13747cab709c9af656725889947e6873d570eb83068ac86e67b48b3397bf83e97479817924435b5efed2f086e07ecb7bc354811a8259b457fbc1596ad7208448a1ec3649fe24733b266e27e7eadcffa1b5c65780a7f0bb58c194ea2044c94a58f643160ed38d606d3edfbf23f6aa0e64024187698014bd665ff3e7,tf-efficientnet/pytorch/tf-efficientnet-b7/1:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-models-data%2F2663%2F3736%2Fbundle%2Farchive.tar.gz%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240514%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240514T073114Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D2be02940ff7a522f151fde1c0513e740242f49dfb893499fca961bfa3b1c44f7059c86c1d262e355c4a2c47543e2f41c69c19921d7880512c4a8d3b074e1299a2a1562f1dc40c4fb9a1b0c5ccbd6d5a14e9371641aa34a7224baab061dcd758f75ef58be0a29dcd1a22d6d3b54b936aeba256efcdd3d1ac6e404477321023cb4994264c342a1f722ad399ea13e98e11c5850f2acef253ce97a549e3fca3d82e3535724901eedb8d694dd39cf28f89c3cb56cf85d95f9be716c1283d155f8301161623b82a39c0bb1cc87c951fcaa4997c060ca119e36fc4038c4af8871acc81d8b48a4d1a08fb30dc07ba3cf80e6ff370fce703f23b7f52b66aaa9b6378cae27,loftr/pytorch/outdoor/1:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-models-data%2F2742%2F3840%2Fbundle%2Farchive.tar.gz%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240514%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240514T073114Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Dabef4968cce2b3e643b4a114ad469f1cead778e24520bda42122ff200363a503c4f2a8293c7ac84b9e0a704d4f87e89367858010da297cc87c6e22a17b28a19d168b41edf9c3fbc9fb9a0269dbacb6cb51ae37aa5e2f2c3385cfcf2660b4773bda0d68d2b3d8a75109d78421770b584ade791d1eb908f3a40e70f6840d46d4bce6d58b26b6b15029bd0fd07243a0ecdd5962510678025bd3306a6387336d722c9f4db385f5e0d72b82a42e79276a3f77e1bb0586a7b8bb9fd7d9a53446c73b867cb8e4e6f55d32c424d16c67059e04982017a323c657919bf40b1610d207f5d5203f1c6916eb5d797d37b2a87dd9d96e99fa05f757883f2ccdf4eab13919b713,disk/pytorch/depth-supervision/1:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-models-data%2F2747%2F3846%2Fbundle%2Farchive.tar.gz%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240514%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240514T073114Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D6d1f498bfc92aaa6156707d831e329e3277523acfe66af0d0d3f2f4313dba8c150ea18f7e65d45b6e4ca81d7c9c49fda05d9590f11006bfa677769018c5bac8ee26f75ccfb4ee8c8b761449c2f570588e41f313f252c06f42d288944aeb18f8ffc4159895f9f76389338c45a150e8d19a60c8f70c5912be9f96c5779c68d21485a408f38fa3ceba9fbe24db5e89ab4e8b93e4c6c0e8b5a40eca388b00ae600914cc44e2ec40a6b66fa2fb605e9dc0c92caeaa503dcdc2b1a7b7d3bca476ecb58841d53ea522890825c90fb0ba42b26b726ec573812f2d332a03319046490d057541e1b6a18ebd3854f3b1ebaa5402bb6241eccd5c5bad490bab98beb905e9fc4,dinov2/pytorch/base/1:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-models-data%2F3326%2F4534%2Fbundle%2Farchive.tar.gz%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240514%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240514T073114Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D64736f45b303be6ad0efebeb7a2000d1cc975cbdce81226a167c05e9a9e6de4e8aebc7d388a881fc6023e0906cb183575b1f37260bd7353e1aaa3ce8f5dbd6f2111e339a9e14fee154885536349fb0150e5812775d2e848f6b4d137842412c82910a7cff2aee03d84db51335c5085a59b378076287d7377d1b9a893de602400e8c5d818258b2aad0a6078067eb7302226944fccc619d59935c4ea172da78d10ad4e5f9759239ddbda439498f649d4f69806a6d29fe546e1c20b1096449bc8381f82b9039122f8995952163392905f71dc1838b8778a92ed690630ccad62f0fb2b83c71e945b3b70bb88f4d3bfc4681278e0544caea1c0483c6f840e8e0d5936f,lightglue/pytorch/aliked/1:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-models-data%2F14317%2F17191%2Fbundle%2Farchive.tar.gz%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240514%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240514T073114Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D9dfedc83b84d7ab5c3f6fe6852891be9f460890527b74984ee0fbb5a6f0f0afa4d7081b9f16c7ccc843558ab8aead81c0a0571e55b5fcda4c933708bd676b552680b2ddc73a946df6354313f3c3095d4ac9b470e824d039eeca56b93850f989b1625bf98af7f334db362167819eefde8b82ba07c4105fc108b044af034a4a87c527074e470a7aba9d5d07ef98ef0ebe5cfda41cfdb4042a509673aa79d80e94e239204bf81c26a15150d3430402a5273c763ffe3593c32a0450df9edfb6f220421272cad32ac4b71f84c1e1eaff162b19fb71090b4641ffe7e6b979a02985b3963f8d347c4c6a189ecd797468969c445d20c9f0c6ad527d524aaec3c5b7db4e5,aliked/pytorch/aliked-n16/1:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-models-data%2F14611%2F17555%2Fbundle%2Farchive.tar.gz%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240514%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240514T073114Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D8f0e9d925f046ba96e8b240b9114134092b520a6de5f17aef04508b00462411fd5e27e40188d7f2151d3353d7fdcfdc256157a70d17b84d9a91c357b9fec88c35d6e34a97382b297f508ac3412766988019483afaf0849517259b265746c1948598f21b50e54041addcd47efbfe6d4cda1767f601105c86d34da141c8f3e0765cd85b71e2e961fb19a740c8d21a43f254d8061b0330b51c83be2ff4f1a5203f76467e4ee4a3fda605b60aee5f540c38732cc0055b4591ced5578ce4f75c484b1ce66517447cfa3b460f4a21e6b1e34c34cc46e186338ecb0e8d6ba5df8647370aef89fba17f252ed5f4245864786ee98dd59bea61a48ac62bff62b9d4c39c72a'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "QCSsCNcHA0ac"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.011573,
          "end_time": "2024-05-01T06:40:24.559539",
          "exception": false,
          "start_time": "2024-05-01T06:40:24.547966",
          "status": "completed"
        },
        "tags": [],
        "id": "H6i6a2M-A0af"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install --no-deps /kaggle/input/dependencies-imc/pycolmap/pycolmap-0.4.0-cp310-cp310-manylinux2014_x86_64.whl\n",
        "!python -m pip install --no-deps /kaggle/input/dependencies-imc/safetensors/safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
        "!python -m pip install --no-index --find-links=/kaggle/input/dependencies-imc/transformers/ transformers > /dev/null\n",
        "!python -m pip install  --no-deps /kaggle/input/imc2024-packages-lightglue-rerun-kornia/lightglue-0.0-py3-none-any.whl\n",
        "\n",
        "# dkm\n",
        "!python -m pip install --no-index --find-links=/kaggle/input/dkm-dependencies/packages einops > /dev/null"
      ],
      "metadata": {
        "papermill": {
          "duration": 92.390632,
          "end_time": "2024-05-01T06:41:56.961738",
          "exception": false,
          "start_time": "2024-05-01T06:40:24.571106",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-05-14T07:24:40.878277Z",
          "iopub.execute_input": "2024-05-14T07:24:40.878651Z",
          "iopub.status.idle": "2024-05-14T07:26:16.521777Z",
          "shell.execute_reply.started": "2024-05-14T07:24:40.878619Z",
          "shell.execute_reply": "2024-05-14T07:26:16.520616Z"
        },
        "trusted": true,
        "id": "qLOxbDVLA0ag",
        "outputId": "bef634e4-85b3-40e2-cf3e-a2eba2d790ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Processing /kaggle/input/dependencies-imc/pycolmap/pycolmap-0.4.0-cp310-cp310-manylinux2014_x86_64.whl\nInstalling collected packages: pycolmap\nSuccessfully installed pycolmap-0.4.0\nProcessing /kaggle/input/dependencies-imc/safetensors/safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nInstalling collected packages: safetensors\n  Attempting uninstall: safetensors\n    Found existing installation: safetensors 0.4.3\n    Uninstalling safetensors-0.4.3:\n      Successfully uninstalled safetensors-0.4.3\nSuccessfully installed safetensors-0.4.1\nProcessing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/lightglue-0.0-py3-none-any.whl\nInstalling collected packages: lightglue\nSuccessfully installed lightglue-0.0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lightglue models\n",
        "!mkdir -p /root/.cache/torch/hub/checkpoints\n",
        "!cp /kaggle/input/aliked/pytorch/aliked-n16/1/* /root/.cache/torch/hub/checkpoints/\n",
        "!cp /kaggle/input/lightglue/pytorch/aliked/1/* /root/.cache/torch/hub/checkpoints/\n",
        "!cp /kaggle/input/lightglue/pytorch/aliked/1/aliked_lightglue.pth /root/.cache/torch/hub/checkpoints/aliked_lightglue_v0-1_arxiv-pth\n",
        "!cp /kaggle/input/pytorch-lightglue-models/* /root/.cache/torch/hub/checkpoints/\n",
        "\n",
        "# dkm model\n",
        "!mkdir -p /root/.cache/torch/hub/checkpoints\n",
        "!cp /kaggle/input/dkm-dependencies/DKMv3_outdoor.pth /root/.cache/torch/hub/checkpoints/"
      ],
      "metadata": {
        "papermill": {
          "duration": 15.15461,
          "end_time": "2024-05-01T06:42:12.128098",
          "exception": false,
          "start_time": "2024-05-01T06:41:56.973488",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-05-14T07:26:16.524043Z",
          "iopub.execute_input": "2024-05-14T07:26:16.524336Z",
          "iopub.status.idle": "2024-05-14T07:26:28.439961Z",
          "shell.execute_reply.started": "2024-05-14T07:26:16.52431Z",
          "shell.execute_reply": "2024-05-14T07:26:28.438746Z"
        },
        "trusted": true,
        "id": "0jqeSJTsA0ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.020301,
          "end_time": "2024-05-01T06:42:12.160155",
          "exception": false,
          "start_time": "2024-05-01T06:42:12.139854",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-05-14T07:26:28.441472Z",
          "iopub.execute_input": "2024-05-14T07:26:28.441827Z",
          "iopub.status.idle": "2024-05-14T07:26:28.448874Z",
          "shell.execute_reply.started": "2024-05-14T07:26:28.441796Z",
          "shell.execute_reply": "2024-05-14T07:26:28.447461Z"
        },
        "trusted": true,
        "id": "nzDksF7-A0ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# General utilities\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from time import time\n",
        "from fastprogress import progress_bar\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import h5py\n",
        "from IPython.display import clear_output\n",
        "from collections import defaultdict\n",
        "from copy import deepcopy\n",
        "\n",
        "# CV/ML\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import kornia as K\n",
        "import kornia.feature as KF\n",
        "from PIL import Image\n",
        "import timm\n",
        "from timm.data import resolve_data_config\n",
        "from timm.data.transforms_factory import create_transform\n",
        "\n",
        "import torchvision\n",
        "\n",
        "# 3D reconstruction\n",
        "import pycolmap\n",
        "\n",
        "import glob\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# dkm\n",
        "import sys\n",
        "sys.path.append('/kaggle/input/dkm-dependencies/DKM/')\n",
        "from dkm.utils.utils import tensor_to_pil, get_tuple_transform_ops\n",
        "from dkm import DKMv3_outdoor\n",
        "\n",
        "# LoFTR\n",
        "from kornia.feature import LoFTR"
      ],
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "papermill": {
          "duration": 9.346589,
          "end_time": "2024-05-01T06:42:21.518858",
          "exception": false,
          "start_time": "2024-05-01T06:42:12.172269",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-05-14T07:26:28.451332Z",
          "iopub.execute_input": "2024-05-14T07:26:28.451634Z",
          "iopub.status.idle": "2024-05-14T07:26:37.508496Z",
          "shell.execute_reply.started": "2024-05-14T07:26:28.451608Z",
          "shell.execute_reply": "2024-05-14T07:26:37.507696Z"
        },
        "trusted": true,
        "id": "ol-uPCRGA0ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightglue import match_pair\n",
        "from lightglue import ALIKED, SuperPoint, DoGHardNet, LightGlue\n",
        "from lightglue.utils import load_image, rbd\n",
        "from kornia.feature import LoFTR"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.022674,
          "end_time": "2024-05-01T06:42:21.553283",
          "exception": false,
          "start_time": "2024-05-01T06:42:21.530609",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-05-14T07:26:37.50994Z",
          "iopub.execute_input": "2024-05-14T07:26:37.51024Z",
          "iopub.status.idle": "2024-05-14T07:26:37.519428Z",
          "shell.execute_reply.started": "2024-05-14T07:26:37.510213Z",
          "shell.execute_reply": "2024-05-14T07:26:37.518626Z"
        },
        "trusted": true,
        "id": "1hszCvJ1A0ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Kornia version', K.__version__)\n",
        "print('Pycolmap version', pycolmap.__version__)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.018364,
          "end_time": "2024-05-01T06:42:21.583113",
          "exception": false,
          "start_time": "2024-05-01T06:42:21.564749",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-05-14T07:26:37.52089Z",
          "iopub.execute_input": "2024-05-14T07:26:37.52147Z",
          "iopub.status.idle": "2024-05-14T07:26:37.533252Z",
          "shell.execute_reply.started": "2024-05-14T07:26:37.521437Z",
          "shell.execute_reply": "2024-05-14T07:26:37.532399Z"
        },
        "trusted": true,
        "id": "D0tOh_AJA0ai",
        "outputId": "2a9333b8-2d1b-4036-b2e6-a068a36b94c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Kornia version 0.7.2\nPycolmap version 0.4.0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configurations"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.01118,
          "end_time": "2024-05-01T06:42:21.605661",
          "exception": false,
          "start_time": "2024-05-01T06:42:21.594481",
          "status": "completed"
        },
        "tags": [],
        "id": "dqtHKfQVA0ai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CONFIG:\n",
        "    use_aliked_lightglue = True\n",
        "    use_doghardnet_lightglue = False\n",
        "    use_superpoint_lightglue = False\n",
        "    use_loftr = False\n",
        "    use_dkm = False\n",
        "    use_superglue = False\n",
        "\n",
        "    params_aliked_lightglue = {\n",
        "        \"num_features\" : 8192,\n",
        "        \"detection_threshold\" : 0.001,\n",
        "        \"min_matches\" : 15,\n",
        "        \"resize_to\" : 1024,\n",
        "    }\n",
        "\n",
        "    params_doghardnet_lightglue = {\n",
        "        \"num_features\" : 8192,\n",
        "        \"detection_threshold\" : 0.001,\n",
        "        \"min_matches\" : 15,\n",
        "        \"resize_to\" : 1024,\n",
        "    }\n",
        "\n",
        "    params_superpoint_lightglue = {\n",
        "        \"num_features\" : 4096,\n",
        "        \"detection_threshold\" : 0.005,\n",
        "        \"min_matches\" : 15,\n",
        "        \"resize_to\" : 1024,\n",
        "    }\n",
        "\n",
        "    params_loftr = {\n",
        "        \"resize_small_edge_to\" : 750,\n",
        "        \"min_matches\" : 15,\n",
        "    }\n",
        "\n",
        "    params_dkm = {\n",
        "        \"num_features\" : 2048,\n",
        "        \"detection_threshold\" : 0.4,\n",
        "        \"min_matches\" : 15,\n",
        "        \"resize_to\" : (540, 720),\n",
        "    }\n",
        "\n",
        "    params_sg = {\n",
        "        \"sg_config\" :\n",
        "        {\n",
        "            \"superpoint\": {\n",
        "                \"nms_radius\": 4,\n",
        "                \"keypoint_threshold\": 0.0001,\n",
        "                \"max_keypoints\": 4096\n",
        "            },\n",
        "            \"superglue\": {\n",
        "                \"weights\": \"outdoor\",\n",
        "                \"sinkhorn_iterations\": 10,\n",
        "                \"match_threshold\": 0.2,\n",
        "            },\n",
        "        },\n",
        "        \"resize_to\": 1240,\n",
        "        \"min_matches\": 15,\n",
        "    }"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.022206,
          "end_time": "2024-05-01T06:42:21.639398",
          "exception": false,
          "start_time": "2024-05-01T06:42:21.617192",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-05-14T07:26:37.534281Z",
          "iopub.execute_input": "2024-05-14T07:26:37.534551Z",
          "iopub.status.idle": "2024-05-14T07:26:37.547122Z",
          "shell.execute_reply.started": "2024-05-14T07:26:37.534506Z",
          "shell.execute_reply": "2024-05-14T07:26:37.546374Z"
        },
        "trusted": true,
        "id": "ud55qOPsA0ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda')"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.017966,
          "end_time": "2024-05-01T06:42:21.668626",
          "exception": false,
          "start_time": "2024-05-01T06:42:21.65066",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-05-14T07:26:37.548125Z",
          "iopub.execute_input": "2024-05-14T07:26:37.548365Z",
          "iopub.status.idle": "2024-05-14T07:26:37.560698Z",
          "shell.execute_reply.started": "2024-05-14T07:26:37.548343Z",
          "shell.execute_reply": "2024-05-14T07:26:37.559773Z"
        },
        "trusted": true,
        "id": "a3jGmpFHA0aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COLMAP utilities"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.011154,
          "end_time": "2024-05-01T06:42:21.691381",
          "exception": false,
          "start_time": "2024-05-01T06:42:21.680227",
          "status": "completed"
        },
        "tags": [],
        "id": "SARxL8sbA0aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to manipulate a colmap database.\n",
        "# Forked from https://github.com/colmap/colmap/blob/dev/scripts/python/database.py\n",
        "\n",
        "# Copyright (c) 2018, ETH Zurich and UNC Chapel Hill.\n",
        "# All rights reserved.\n",
        "#\n",
        "# Redistribution and use in source and binary forms, with or without\n",
        "# modification, are permitted provided that the following conditions are met:\n",
        "#\n",
        "#     * Redistributions of source code must retain the above copyright\n",
        "#       notice, this list of conditions and the following disclaimer.\n",
        "#\n",
        "#     * Redistributions in binary form must reproduce the above copyright\n",
        "#       notice, this list of conditions and the following disclaimer in the\n",
        "#       documentation and/or other materials provided with the distribution.\n",
        "#\n",
        "#     * Neither the name of ETH Zurich and UNC Chapel Hill nor the names of\n",
        "#       its contributors may be used to endorse or promote products derived\n",
        "#       from this software without specific prior written permission.\n",
        "#\n",
        "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
        "# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
        "# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n",
        "# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE\n",
        "# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n",
        "# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n",
        "# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n",
        "# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n",
        "# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n",
        "# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
        "# POSSIBILITY OF SUCH DAMAGE.\n",
        "#\n",
        "# Author: Johannes L. Schoenberger (jsch-at-demuc-dot-de)\n",
        "\n",
        "# This script is based on an original implementation by True Price.\n",
        "\n",
        "import sys\n",
        "import sqlite3\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "IS_PYTHON3 = sys.version_info[0] >= 3\n",
        "\n",
        "MAX_IMAGE_ID = 2**31 - 1\n",
        "\n",
        "CREATE_CAMERAS_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS cameras (\n",
        "    camera_id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
        "    model INTEGER NOT NULL,\n",
        "    width INTEGER NOT NULL,\n",
        "    height INTEGER NOT NULL,\n",
        "    params BLOB,\n",
        "    prior_focal_length INTEGER NOT NULL)\"\"\"\n",
        "\n",
        "CREATE_DESCRIPTORS_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS descriptors (\n",
        "    image_id INTEGER PRIMARY KEY NOT NULL,\n",
        "    rows INTEGER NOT NULL,\n",
        "    cols INTEGER NOT NULL,\n",
        "    data BLOB,\n",
        "    FOREIGN KEY(image_id) REFERENCES images(image_id) ON DELETE CASCADE)\"\"\"\n",
        "\n",
        "CREATE_IMAGES_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS images (\n",
        "    image_id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
        "    name TEXT NOT NULL UNIQUE,\n",
        "    camera_id INTEGER NOT NULL,\n",
        "    prior_qw REAL,\n",
        "    prior_qx REAL,\n",
        "    prior_qy REAL,\n",
        "    prior_qz REAL,\n",
        "    prior_tx REAL,\n",
        "    prior_ty REAL,\n",
        "    prior_tz REAL,\n",
        "    CONSTRAINT image_id_check CHECK(image_id >= 0 and image_id < {}),\n",
        "    FOREIGN KEY(camera_id) REFERENCES cameras(camera_id))\n",
        "\"\"\".format(MAX_IMAGE_ID)\n",
        "\n",
        "CREATE_TWO_VIEW_GEOMETRIES_TABLE = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS two_view_geometries (\n",
        "    pair_id INTEGER PRIMARY KEY NOT NULL,\n",
        "    rows INTEGER NOT NULL,\n",
        "    cols INTEGER NOT NULL,\n",
        "    data BLOB,\n",
        "    config INTEGER NOT NULL,\n",
        "    F BLOB,\n",
        "    E BLOB,\n",
        "    H BLOB)\n",
        "\"\"\"\n",
        "\n",
        "CREATE_KEYPOINTS_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS keypoints (\n",
        "    image_id INTEGER PRIMARY KEY NOT NULL,\n",
        "    rows INTEGER NOT NULL,\n",
        "    cols INTEGER NOT NULL,\n",
        "    data BLOB,\n",
        "    FOREIGN KEY(image_id) REFERENCES images(image_id) ON DELETE CASCADE)\n",
        "\"\"\"\n",
        "\n",
        "CREATE_MATCHES_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS matches (\n",
        "    pair_id INTEGER PRIMARY KEY NOT NULL,\n",
        "    rows INTEGER NOT NULL,\n",
        "    cols INTEGER NOT NULL,\n",
        "    data BLOB)\"\"\"\n",
        "\n",
        "CREATE_NAME_INDEX = \\\n",
        "    \"CREATE UNIQUE INDEX IF NOT EXISTS index_name ON images(name)\"\n",
        "\n",
        "CREATE_ALL = \"; \".join([\n",
        "    CREATE_CAMERAS_TABLE,\n",
        "    CREATE_IMAGES_TABLE,\n",
        "    CREATE_KEYPOINTS_TABLE,\n",
        "    CREATE_DESCRIPTORS_TABLE,\n",
        "    CREATE_MATCHES_TABLE,\n",
        "    CREATE_TWO_VIEW_GEOMETRIES_TABLE,\n",
        "    CREATE_NAME_INDEX\n",
        "])\n",
        "\n",
        "\n",
        "def image_ids_to_pair_id(image_id1, image_id2):\n",
        "    if image_id1 > image_id2:\n",
        "        image_id1, image_id2 = image_id2, image_id1\n",
        "    return image_id1 * MAX_IMAGE_ID + image_id2\n",
        "\n",
        "\n",
        "def pair_id_to_image_ids(pair_id):\n",
        "    image_id2 = pair_id % MAX_IMAGE_ID\n",
        "    image_id1 = (pair_id - image_id2) / MAX_IMAGE_ID\n",
        "    return image_id1, image_id2\n",
        "\n",
        "\n",
        "def array_to_blob(array):\n",
        "    if IS_PYTHON3:\n",
        "        return array.tostring()\n",
        "    else:\n",
        "        return np.getbuffer(array)\n",
        "\n",
        "\n",
        "def blob_to_array(blob, dtype, shape=(-1,)):\n",
        "    if IS_PYTHON3:\n",
        "        return np.fromstring(blob, dtype=dtype).reshape(*shape)\n",
        "    else:\n",
        "        return np.frombuffer(blob, dtype=dtype).reshape(*shape)\n",
        "\n",
        "\n",
        "class COLMAPDatabase(sqlite3.Connection):\n",
        "\n",
        "    @staticmethod\n",
        "    def connect(database_path):\n",
        "        return sqlite3.connect(database_path, factory=COLMAPDatabase)\n",
        "\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(COLMAPDatabase, self).__init__(*args, **kwargs)\n",
        "\n",
        "        self.create_tables = lambda: self.executescript(CREATE_ALL)\n",
        "        self.create_cameras_table = \\\n",
        "            lambda: self.executescript(CREATE_CAMERAS_TABLE)\n",
        "        self.create_descriptors_table = \\\n",
        "            lambda: self.executescript(CREATE_DESCRIPTORS_TABLE)\n",
        "        self.create_images_table = \\\n",
        "            lambda: self.executescript(CREATE_IMAGES_TABLE)\n",
        "        self.create_two_view_geometries_table = \\\n",
        "            lambda: self.executescript(CREATE_TWO_VIEW_GEOMETRIES_TABLE)\n",
        "        self.create_keypoints_table = \\\n",
        "            lambda: self.executescript(CREATE_KEYPOINTS_TABLE)\n",
        "        self.create_matches_table = \\\n",
        "            lambda: self.executescript(CREATE_MATCHES_TABLE)\n",
        "        self.create_name_index = lambda: self.executescript(CREATE_NAME_INDEX)\n",
        "\n",
        "    def add_camera(self, model, width, height, params,\n",
        "                   prior_focal_length=False, camera_id=None):\n",
        "        params = np.asarray(params, np.float64)\n",
        "        cursor = self.execute(\n",
        "            \"INSERT INTO cameras VALUES (?, ?, ?, ?, ?, ?)\",\n",
        "            (camera_id, model, width, height, array_to_blob(params),\n",
        "             prior_focal_length))\n",
        "        return cursor.lastrowid\n",
        "\n",
        "    def add_image(self, name, camera_id,\n",
        "                  prior_q=np.zeros(4), prior_t=np.zeros(3), image_id=None):\n",
        "        cursor = self.execute(\n",
        "            \"INSERT INTO images VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\",\n",
        "            (image_id, name, camera_id, prior_q[0], prior_q[1], prior_q[2],\n",
        "             prior_q[3], prior_t[0], prior_t[1], prior_t[2]))\n",
        "        return cursor.lastrowid\n",
        "\n",
        "    def add_keypoints(self, image_id, keypoints):\n",
        "        assert(len(keypoints.shape) == 2)\n",
        "        assert(keypoints.shape[1] in [2, 4, 6])\n",
        "\n",
        "        keypoints = np.asarray(keypoints, np.float32)\n",
        "        self.execute(\n",
        "            \"INSERT INTO keypoints VALUES (?, ?, ?, ?)\",\n",
        "            (image_id,) + keypoints.shape + (array_to_blob(keypoints),))\n",
        "\n",
        "    def add_descriptors(self, image_id, descriptors):\n",
        "        descriptors = np.ascontiguousarray(descriptors, np.uint8)\n",
        "        self.execute(\n",
        "            \"INSERT INTO descriptors VALUES (?, ?, ?, ?)\",\n",
        "            (image_id,) + descriptors.shape + (array_to_blob(descriptors),))\n",
        "\n",
        "    def add_matches(self, image_id1, image_id2, matches):\n",
        "        assert(len(matches.shape) == 2)\n",
        "        assert(matches.shape[1] == 2)\n",
        "\n",
        "        if image_id1 > image_id2:\n",
        "            matches = matches[:,::-1]\n",
        "\n",
        "        pair_id = image_ids_to_pair_id(image_id1, image_id2)\n",
        "        matches = np.asarray(matches, np.uint32)\n",
        "        self.execute(\n",
        "            \"INSERT INTO matches VALUES (?, ?, ?, ?)\",\n",
        "            (pair_id,) + matches.shape + (array_to_blob(matches),))\n",
        "\n",
        "    def add_two_view_geometry(self, image_id1, image_id2, matches,\n",
        "                              F=np.eye(3), E=np.eye(3), H=np.eye(3), config=2):\n",
        "        assert(len(matches.shape) == 2)\n",
        "        assert(matches.shape[1] == 2)\n",
        "\n",
        "        if image_id1 > image_id2:\n",
        "            matches = matches[:,::-1]\n",
        "\n",
        "        pair_id = image_ids_to_pair_id(image_id1, image_id2)\n",
        "        matches = np.asarray(matches, np.uint32)\n",
        "        F = np.asarray(F, dtype=np.float64)\n",
        "        E = np.asarray(E, dtype=np.float64)\n",
        "        H = np.asarray(H, dtype=np.float64)\n",
        "        self.execute(\n",
        "            \"INSERT INTO two_view_geometries VALUES (?, ?, ?, ?, ?, ?, ?, ?)\",\n",
        "            (pair_id,) + matches.shape + (array_to_blob(matches), config,\n",
        "             array_to_blob(F), array_to_blob(E), array_to_blob(H)))"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "papermill": {
          "duration": 0.042154,
          "end_time": "2024-05-01T06:42:21.745229",
          "exception": false,
          "start_time": "2024-05-01T06:42:21.703075",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-05-14T07:26:37.562138Z",
          "iopub.execute_input": "2024-05-14T07:26:37.562442Z",
          "iopub.status.idle": "2024-05-14T07:26:37.593002Z",
          "shell.execute_reply.started": "2024-05-14T07:26:37.562418Z",
          "shell.execute_reply": "2024-05-14T07:26:37.592069Z"
        },
        "trusted": true,
        "id": "mWkhoKjwA0aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# h5 to colmap db"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.010944,
          "end_time": "2024-05-01T06:42:21.767649",
          "exception": false,
          "start_time": "2024-05-01T06:42:21.756705",
          "status": "completed"
        },
        "tags": [],
        "id": "TEuivBEpA0ak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to interface DISK with Colmap.\n",
        "# Forked from https://github.com/cvlab-epfl/disk/blob/37f1f7e971cea3055bb5ccfc4cf28bfd643fa339/colmap/h5_to_db.py\n",
        "\n",
        "#  Copyright [2020] [Micha≈Ç Tyszkiewicz, Pascal Fua, Eduard Trulls]\n",
        "#\n",
        "#   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "#   you may not use this file except in compliance with the License.\n",
        "#   You may obtain a copy of the License at\n",
        "#\n",
        "#       http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "#   Unless required by applicable law or agreed to in writing, software\n",
        "#   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "#   See the License for the specific language governing permissions and\n",
        "#   limitations under the License.\n",
        "\n",
        "import os, argparse, h5py, warnings\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, ExifTags\n",
        "\n",
        "\n",
        "def get_focal(image_path, err_on_default=False):\n",
        "    image         = Image.open(image_path)\n",
        "    max_size      = max(image.size)\n",
        "\n",
        "    exif = image.getexif()\n",
        "    focal = None\n",
        "    if exif is not None:\n",
        "        focal_35mm = None\n",
        "        # https://github.com/colmap/colmap/blob/d3a29e203ab69e91eda938d6e56e1c7339d62a99/src/util/bitmap.cc#L299\n",
        "        for tag, value in exif.items():\n",
        "            focal_35mm = None\n",
        "            if ExifTags.TAGS.get(tag, None) == 'FocalLengthIn35mmFilm':\n",
        "                focal_35mm = float(value)\n",
        "                break\n",
        "\n",
        "        if focal_35mm is not None:\n",
        "            focal = focal_35mm / 35. * max_size\n",
        "\n",
        "    if focal is None:\n",
        "        if err_on_default:\n",
        "            raise RuntimeError(\"Failed to find focal length\")\n",
        "\n",
        "        # failed to find it in exif, use prior\n",
        "        FOCAL_PRIOR = 1.2\n",
        "        focal = FOCAL_PRIOR * max_size\n",
        "\n",
        "    return focal\n",
        "\n",
        "def create_camera(db, image_path, camera_model):\n",
        "    image         = Image.open(image_path)\n",
        "    width, height = image.size\n",
        "\n",
        "    focal = get_focal(image_path)\n",
        "\n",
        "    if camera_model == 'simple-pinhole':\n",
        "        model = 0 # simple pinhole\n",
        "        param_arr = np.array([focal, width / 2, height / 2])\n",
        "    if camera_model == 'pinhole':\n",
        "        model = 1 # pinhole\n",
        "        param_arr = np.array([focal, focal, width / 2, height / 2])\n",
        "    elif camera_model == 'simple-radial':\n",
        "        model = 2 # simple radial\n",
        "        param_arr = np.array([focal, width / 2, height / 2, 0.1])\n",
        "    elif camera_model == 'opencv':\n",
        "        model = 4 # opencv\n",
        "        param_arr = np.array([focal, focal, width / 2, height / 2, 0., 0., 0., 0.])\n",
        "\n",
        "    return db.add_camera(model, width, height, param_arr)\n",
        "\n",
        "\n",
        "def add_keypoints(db, h5_path, image_path, img_ext, camera_model, single_camera = True):\n",
        "    keypoint_f = h5py.File(os.path.join(h5_path, 'keypoints.h5'), 'r')\n",
        "\n",
        "    camera_id = None\n",
        "    fname_to_id = {}\n",
        "    for filename in tqdm(list(keypoint_f.keys())):\n",
        "        keypoints = keypoint_f[filename][()]\n",
        "\n",
        "        fname_with_ext = filename# + img_ext\n",
        "        path = os.path.join(image_path, fname_with_ext)\n",
        "        if not os.path.isfile(path):\n",
        "            raise IOError(f'Invalid image path {path}')\n",
        "\n",
        "        if camera_id is None or not single_camera:\n",
        "            camera_id = create_camera(db, path, camera_model)\n",
        "        image_id = db.add_image(fname_with_ext, camera_id)\n",
        "        fname_to_id[filename] = image_id\n",
        "\n",
        "        db.add_keypoints(image_id, keypoints)\n",
        "\n",
        "    return fname_to_id\n",
        "\n",
        "def add_matches(db, h5_path, fname_to_id):\n",
        "    match_file = h5py.File(os.path.join(h5_path, 'matches.h5'), 'r')\n",
        "\n",
        "    added = set()\n",
        "    n_keys = len(match_file.keys())\n",
        "    n_total = (n_keys * (n_keys - 1)) // 2\n",
        "\n",
        "    with tqdm(total=n_total) as pbar:\n",
        "        for key_1 in match_file.keys():\n",
        "            group = match_file[key_1]\n",
        "            for key_2 in group.keys():\n",
        "                id_1 = fname_to_id[key_1]\n",
        "                id_2 = fname_to_id[key_2]\n",
        "\n",
        "                pair_id = image_ids_to_pair_id(id_1, id_2)\n",
        "                if pair_id in added:\n",
        "                    warnings.warn(f'Pair {pair_id} ({id_1}, {id_2}) already added!')\n",
        "                    continue\n",
        "\n",
        "                matches = group[key_2][()]\n",
        "                db.add_matches(id_1, id_2, matches)\n",
        "\n",
        "                added.add(pair_id)\n",
        "\n",
        "                pbar.update(1)\n",
        "\n",
        "def import_into_colmap(img_dir,\n",
        "                       feature_dir ='.featureout',\n",
        "                       database_path = 'colmap.db',\n",
        "                       img_ext='.jpg'):\n",
        "    db = COLMAPDatabase.connect(database_path)\n",
        "    db.create_tables()\n",
        "    single_camera = False\n",
        "    fname_to_id = add_keypoints(db, feature_dir, img_dir, img_ext, 'simple-radial', single_camera)\n",
        "    add_matches(\n",
        "        db,\n",
        "        feature_dir,\n",
        "        fname_to_id,\n",
        "    )\n",
        "\n",
        "    db.commit()\n",
        "    return"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "papermill": {
          "duration": 0.034268,
          "end_time": "2024-05-01T06:42:21.813253",
          "exception": false,
          "start_time": "2024-05-01T06:42:21.778985",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-05-14T07:26:37.597729Z",
          "iopub.execute_input": "2024-05-14T07:26:37.597988Z",
          "iopub.status.idle": "2024-05-14T07:26:37.621493Z",
          "shell.execute_reply.started": "2024-05-14T07:26:37.597966Z",
          "shell.execute_reply": "2024-05-14T07:26:37.620576Z"
        },
        "trusted": true,
        "id": "W7agM0FxA0ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Pairs"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.010948,
          "end_time": "2024-05-01T06:42:21.835489",
          "exception": false,
          "start_time": "2024-05-01T06:42:21.824541",
          "status": "completed"
        },
        "tags": [],
        "id": "-bcuGhcXA0al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will use ViT global descriptor to get matching shortlists.\n",
        "def get_global_desc(fnames, model,\n",
        "                    device =  torch.device('cpu')):\n",
        "    model = model.eval()\n",
        "    model= model.to(device)\n",
        "    config = resolve_data_config({}, model=model)\n",
        "    transform = create_transform(**config)\n",
        "    global_descs_convnext=[]\n",
        "    for i, img_fname_full in tqdm(enumerate(fnames),total= len(fnames)):\n",
        "        key = os.path.splitext(os.path.basename(img_fname_full))[0]\n",
        "        img = Image.open(img_fname_full).convert('RGB')\n",
        "        timg = transform(img).unsqueeze(0).to(device)\n",
        "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
        "            desc = model.forward_features(timg.to(device)).mean(dim=(-1,2))#\n",
        "            #print (desc.shape)\n",
        "            desc = desc.view(1, -1)\n",
        "            desc_norm = F.normalize(desc, dim=1, p=2)\n",
        "        #print (desc_norm)\n",
        "        global_descs_convnext.append(desc_norm.detach().cpu())\n",
        "    global_descs_all = torch.cat(global_descs_convnext, dim=0)\n",
        "    return global_descs_all.to(torch.float32)\n",
        "\n",
        "def convert_1d_to_2d(idx, num_images):\n",
        "    idx1 = idx // num_images\n",
        "    idx2 = idx % num_images\n",
        "    return (idx1, idx2)\n",
        "\n",
        "def get_pairs_from_distancematrix(mat):\n",
        "    pairs = [ convert_1d_to_2d(idx, mat.shape[0]) for idx in np.argsort(mat.flatten())]\n",
        "    pairs = [ pair for pair in pairs if pair[0] < pair[1] ]\n",
        "    return pairs\n",
        "\n",
        "def get_img_pairs_exhaustive(img_fnames, model, device):\n",
        "    #index_pairs = []\n",
        "    #for i in range(len(img_fnames)):\n",
        "    #    for j in range(i+1, len(img_fnames)):\n",
        "    #        index_pairs.append((i,j))\n",
        "    #return index_pairs\n",
        "    descs = get_global_desc(img_fnames, model, device=device)\n",
        "    dm = torch.cdist(descs, descs, p=2).detach().cpu().numpy()\n",
        "    matching_list = get_pairs_from_distancematrix(dm)\n",
        "    return matching_list\n",
        "\n",
        "\n",
        "def get_image_pairs_shortlist(fnames,\n",
        "                              sim_th = 0.6, # should be strict\n",
        "                              min_pairs = 20,\n",
        "                              exhaustive_if_less = 20,\n",
        "                              device=torch.device('cpu')):\n",
        "    num_imgs = len(fnames)\n",
        "\n",
        "    model = timm.create_model('tf_efficientnet_b7',\n",
        "                              checkpoint_path='/kaggle/input/tf-efficientnet/pytorch/tf-efficientnet-b7/1/tf_efficientnet_b7_ra-6c08e654.pth')\n",
        "    model.eval()\n",
        "    descs = get_global_desc(fnames, model, device=device)\n",
        "\n",
        "    if num_imgs <= exhaustive_if_less:\n",
        "        return get_img_pairs_exhaustive(fnames, model, device)\n",
        "\n",
        "    dm = torch.cdist(descs, descs, p=2).detach().cpu().numpy()\n",
        "    # removing half\n",
        "    mask = dm <= sim_th\n",
        "    total = 0\n",
        "    matching_list = []\n",
        "    ar = np.arange(num_imgs)\n",
        "    already_there_set = []\n",
        "    for st_idx in range(num_imgs-1):\n",
        "        mask_idx = mask[st_idx]\n",
        "        to_match = ar[mask_idx]\n",
        "        if len(to_match) < min_pairs:\n",
        "            to_match = np.argsort(dm[st_idx])[:min_pairs]\n",
        "        for idx in to_match:\n",
        "            if st_idx == idx:\n",
        "                continue\n",
        "            if dm[st_idx, idx] < 1000:\n",
        "                matching_list.append(tuple(sorted((st_idx, idx.item()))))\n",
        "                total+=1\n",
        "    matching_list = sorted(list(set(matching_list)))\n",
        "    return matching_list"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.031338,
          "end_time": "2024-05-01T06:42:21.878007",
          "exception": false,
          "start_time": "2024-05-01T06:42:21.846669",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-05-14T07:26:37.622831Z",
          "iopub.execute_input": "2024-05-14T07:26:37.623252Z",
          "iopub.status.idle": "2024-05-14T07:26:37.642256Z",
          "shell.execute_reply.started": "2024-05-14T07:26:37.623224Z",
          "shell.execute_reply": "2024-05-14T07:26:37.641281Z"
        },
        "trusted": true,
        "id": "IGGyxE-4A0al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keypoints: LightGlue series"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.011018,
          "end_time": "2024-05-01T06:42:21.900318",
          "exception": false,
          "start_time": "2024-05-01T06:42:21.8893",
          "status": "completed"
        },
        "tags": [],
        "id": "Bf31xliKA0al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_torch_image(fname, device=torch.device('cpu')):\n",
        "    img = K.io.load_image(fname, K.io.ImageLoadType.RGB32, device=device)[None, ...]\n",
        "    return img\n",
        "\n",
        "def detect_common(img_fnames,\n",
        "                  model_name,\n",
        "                  feature_dir = '.featureout',\n",
        "                  num_features = 4096,\n",
        "                  resize_to = 1024,\n",
        "                  detection_threshold = 0.01,\n",
        "                  device=torch.device('cpu')):\n",
        "\n",
        "    dict_model = {\n",
        "        \"aliked\" : ALIKED,\n",
        "        \"superpoint\" : SuperPoint,\n",
        "        \"doghardnet\" : DoGHardNet,\n",
        "    }\n",
        "    extractor_class = dict_model[model_name]\n",
        "\n",
        "    dtype = torch.float32 # ALIKED has issues with float16\n",
        "    extractor = extractor_class(\n",
        "        max_num_keypoints=num_features, detection_threshold=detection_threshold, resize=resize_to\n",
        "    ).eval().to(device, dtype)\n",
        "    if not os.path.isdir(feature_dir):\n",
        "        os.makedirs(feature_dir)\n",
        "    with h5py.File(f'{feature_dir}/keypoints_{model_name}.h5', mode='w') as f_kp, \\\n",
        "         h5py.File(f'{feature_dir}/descriptors_{model_name}.h5', mode='w') as f_desc:\n",
        "        for img_path in tqdm(img_fnames):\n",
        "            img_fname = img_path.split('/')[-1]\n",
        "            key = img_fname\n",
        "            with torch.inference_mode():\n",
        "                image0 = load_torch_image(img_path, device=device).to(dtype)\n",
        "                feats0 = extractor.extract(image0)  # auto-resize the image, disable with resize=None\n",
        "                kpts = feats0['keypoints'].reshape(-1, 2).detach().cpu().numpy()\n",
        "                descs = feats0['descriptors'].reshape(len(kpts), -1).detach().cpu().numpy()\n",
        "                f_kp[key] = kpts\n",
        "                f_desc[key] = descs\n",
        "                print(f\"{model_name} > kpts.shape={kpts.shape}, descs.shape={descs.shape}\")\n",
        "    return\n",
        "\n",
        "def match_with_lightglue_common(img_fnames, model_name,\n",
        "                   index_pairs, file_keypoints,\n",
        "                   feature_dir = '.featureout',\n",
        "                   device=torch.device('cpu'),\n",
        "                   min_matches=15,verbose=True):\n",
        "    lg_matcher = KF.LightGlueMatcher(model_name, {\"width_confidence\": -1,\n",
        "                                                \"depth_confidence\": -1,\n",
        "                                                 \"mp\": True if 'cuda' in str(device) else False}).eval().to(device)\n",
        "\n",
        "    cnt_pairs = 0\n",
        "    with h5py.File(f'{feature_dir}/keypoints_{model_name}.h5', mode='r') as f_kp, \\\n",
        "        h5py.File(f'{feature_dir}/descriptors_{model_name}.h5', mode='r') as f_desc, \\\n",
        "        h5py.File(file_keypoints, mode='w') as f_match:\n",
        "        for pair_idx in tqdm(index_pairs):\n",
        "            idx1, idx2 = pair_idx\n",
        "            fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n",
        "\n",
        "            key1, key2 = fname1.split('/')[-1], fname2.split('/')[-1]\n",
        "            kp1 = torch.from_numpy(f_kp[key1][...]).to(device)\n",
        "            kp2 = torch.from_numpy(f_kp[key2][...]).to(device)\n",
        "            desc1 = torch.from_numpy(f_desc[key1][...]).to(device)\n",
        "            desc2 = torch.from_numpy(f_desc[key2][...]).to(device)\n",
        "            with torch.inference_mode():\n",
        "                dists, idxs = lg_matcher(desc1,\n",
        "                                         desc2,\n",
        "                                         KF.laf_from_center_scale_ori(kp1[None]),\n",
        "                                         KF.laf_from_center_scale_ori(kp2[None]))\n",
        "            if len(idxs)  == 0:\n",
        "                continue\n",
        "            n_matches = len(idxs)\n",
        "            kp1 = kp1[idxs[:,0], :].cpu().numpy().reshape(-1, 2).astype(np.float32)\n",
        "            kp2 = kp2[idxs[:,1], :].cpu().numpy().reshape(-1, 2).astype(np.float32)\n",
        "            group  = f_match.require_group(key1)\n",
        "            if n_matches >= min_matches:\n",
        "                group.create_dataset(key2, data=np.concatenate([kp1, kp2], axis=1))\n",
        "                cnt_pairs+=1\n",
        "                print (f'{key1}-{key2}: {n_matches} matches @ {cnt_pairs}th pair({model_name}+lightglue)')\n",
        "            else:\n",
        "                print (f'{key1}-{key2}: {n_matches} matches --> skipped')\n",
        "    return\n",
        "\n",
        "def detect_lightglue_common(\n",
        "    img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints,\n",
        "    resize_to=1024,\n",
        "    detection_threshold=0.01,\n",
        "    num_features=4096,\n",
        "    min_matches=15,\n",
        "):\n",
        "    t=time()\n",
        "    detect_common(\n",
        "        img_fnames, model_name, feature_dir,\n",
        "        resize_to=resize_to,\n",
        "        num_features=num_features,\n",
        "        detection_threshold=detection_threshold,\n",
        "        device=device\n",
        "    )\n",
        "    gc.collect()\n",
        "    match_with_lightglue_common(\n",
        "        img_fnames, model_name, index_pairs, file_keypoints,\n",
        "        feature_dir=feature_dir,\n",
        "        min_matches=min_matches,\n",
        "        device=device\n",
        "    )\n",
        "    t=time() -t\n",
        "    print(f'Features matched in  {t:.4f} sec ({model_name}+LightGlue)')\n",
        "    return t"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "papermill": {
          "duration": 0.036203,
          "end_time": "2024-05-01T06:42:21.948706",
          "exception": false,
          "start_time": "2024-05-01T06:42:21.912503",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-05-14T07:26:37.643593Z",
          "iopub.execute_input": "2024-05-14T07:26:37.643884Z",
          "iopub.status.idle": "2024-05-14T07:26:37.669292Z",
          "shell.execute_reply.started": "2024-05-14T07:26:37.643858Z",
          "shell.execute_reply": "2024-05-14T07:26:37.668171Z"
        },
        "trusted": true,
        "id": "WxTbNN-uA0al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keypoints: SuperGlue"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.011542,
          "end_time": "2024-05-01T06:42:21.971721",
          "exception": false,
          "start_time": "2024-05-01T06:42:21.960179",
          "status": "completed"
        },
        "tags": [],
        "id": "wpvlV1F8A0am"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"../input/super-glue-pretrained-network\")\n",
        "from models.matching import Matching\n",
        "from models.utils import (compute_pose_error, compute_epipolar_error,\n",
        "                          estimate_pose, make_matching_plot,\n",
        "                          error_colormap, AverageTimer, pose_auc, read_image,\n",
        "                          process_resize, frame2tensor,\n",
        "                          rotate_intrinsics, rotate_pose_inplane,\n",
        "                          scale_intrinsics)\n",
        "\n",
        "from torch.nn import functional as torchF  # For resizing tensor\n",
        "\n",
        "def sg_imread(path):\n",
        "    image = cv2.imread(str(path), cv2.IMREAD_GRAYSCALE)\n",
        "    return image\n",
        "\n",
        "# Preprocess\n",
        "def sg_read_image(image, device, resize):\n",
        "    w, h = image.shape[1], image.shape[0]\n",
        "    w_new, h_new = process_resize(w, h, [resize,])\n",
        "\n",
        "    unit_shape = 8\n",
        "    w_new = w_new // unit_shape * unit_shape\n",
        "    h_new = h_new // unit_shape * unit_shape\n",
        "\n",
        "    scales = (float(w) / float(w_new), float(h) / float(h_new))\n",
        "    image = cv2.resize(image.astype('float32'), (w_new, h_new))\n",
        "\n",
        "    inp = frame2tensor(image, \"cpu\")\n",
        "    return image, inp, scales, (h, w)\n",
        "\n",
        "class SGDataset(Dataset):\n",
        "    def __init__(self, fnames1, fnames2, resize_to, device):\n",
        "        self.fnames1 = fnames1\n",
        "        self.fnames2 = fnames2\n",
        "        self.resize_to = resize_to\n",
        "        self.device = device\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.fnames1)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname1 = self.fnames1[idx]\n",
        "        fname2 = self.fnames2[idx]\n",
        "\n",
        "        im1, im2 = cv2.imread(fname1, cv2.IMREAD_GRAYSCALE), cv2.imread(fname2, cv2.IMREAD_GRAYSCALE)\n",
        "        _, image1, scale1, ori_shape1 = sg_read_image(im1, self.device, self.resize_to)\n",
        "        _, image2, scale2, ori_shape2 = sg_read_image(im2, self.device, self.resize_to)\n",
        "        return image1, image2, torch.tensor([idx]), torch.tensor(ori_shape1), torch.tensor(ori_shape2)\n",
        "\n",
        "def get_superglue_dataloader(images1, images2, resize_to, device, batch_size=1):\n",
        "    dataset = SGDataset(images1, images2, resize_to, device)\n",
        "    dataloader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        shuffle=False,\n",
        "        batch_size=batch_size,\n",
        "        pin_memory=True,\n",
        "        num_workers=2,\n",
        "        drop_last=False\n",
        "    )\n",
        "    return dataloader\n",
        "\n",
        "def detect_superglue(\n",
        "    img_fnames, index_pairs, feature_dir, device, sg_config, file_keypoints,\n",
        "    resize_to=750, min_matches=15\n",
        "):\n",
        "    t=time()\n",
        "\n",
        "    matcher_superglue = Matching(sg_config).eval().to(device)\n",
        "\n",
        "    fnames1, fnames2, idxs1, idxs2 = [], [], [], []\n",
        "    for pair_idx in progress_bar(index_pairs):\n",
        "        idx1, idx2 = pair_idx\n",
        "        fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n",
        "        fnames1.append(fname1)\n",
        "        fnames2.append(fname2)\n",
        "        idxs1.append(idx1)\n",
        "        idxs2.append(idx2)\n",
        "\n",
        "    dataloader = get_superglue_dataloader( fnames1, fnames2, resize_to, device)\n",
        "\n",
        "    cnt_pairs = 0\n",
        "\n",
        "    with h5py.File(file_keypoints, mode='w') as f_match:\n",
        "        for X in dataloader:\n",
        "            image1, image2, idx, ori_shape_1, ori_shape_2 = X\n",
        "\n",
        "            fname1, fname2 = fnames1[idx], fnames2[idx]\n",
        "            key1, key2 = fname1.split('/')[-1], fname2.split('/')[-1]\n",
        "\n",
        "            pred = matcher_superglue({\"image0\": image1[0].to(device), \"image1\": image2[0].to(device)})\n",
        "            pred = {k: v[0].detach().cpu().numpy().copy() for k, v in pred.items()}\n",
        "            mkpts1, mkpts2 = pred[\"keypoints0\"], pred[\"keypoints1\"]\n",
        "            matches, conf = pred[\"matches0\"], pred[\"matching_scores0\"]\n",
        "\n",
        "            valid = matches > -1\n",
        "            mkpts1 = mkpts1[valid]\n",
        "            mkpts2 = mkpts2[matches[valid]]\n",
        "            mconf = conf[valid]\n",
        "\n",
        "            ori_shape_1 = ori_shape_1[0].numpy()\n",
        "            ori_shape_2 = ori_shape_2[0].numpy()\n",
        "\n",
        "            # Scaling coords\n",
        "            mkpts1[:,0] = mkpts1[:,0] * ori_shape_1[1] / image1[0].shape[3]   # X\n",
        "            mkpts1[:,1] = mkpts1[:,1] * ori_shape_1[0] / image1[0].shape[2]   # Y\n",
        "            mkpts2[:,0] = mkpts2[:,0] * ori_shape_2[1] / image2[0].shape[3]   # X\n",
        "            mkpts2[:,1] = mkpts2[:,1] * ori_shape_2[0] / image2[0].shape[2]   # Y\n",
        "\n",
        "            n_matches = mconf.shape[0]\n",
        "\n",
        "            group  = f_match.require_group(key1)\n",
        "            if n_matches >= min_matches:\n",
        "                group.create_dataset(key2, data=np.concatenate([mkpts1, mkpts2], axis=1).astype(np.float32))\n",
        "                cnt_pairs+=1\n",
        "                print (f'{key1}-{key2}: {n_matches} matches @ {cnt_pairs}th pair(superglue)')\n",
        "            else:\n",
        "                print (f'{key1}-{key2}: {n_matches} matches --> skipped')\n",
        "\n",
        "    gc.collect()\n",
        "    t=time() -t\n",
        "    print(f'Features matched in  {t:.4f} sec')\n",
        "    return t"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "papermill": {
          "duration": 0.127703,
          "end_time": "2024-05-01T06:42:22.110949",
          "exception": false,
          "start_time": "2024-05-01T06:42:21.983246",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-05-14T07:26:37.670807Z",
          "iopub.execute_input": "2024-05-14T07:26:37.67109Z",
          "iopub.status.idle": "2024-05-14T07:26:37.735043Z",
          "shell.execute_reply.started": "2024-05-14T07:26:37.671065Z",
          "shell.execute_reply": "2024-05-14T07:26:37.734097Z"
        },
        "trusted": true,
        "id": "0nv6fu5pA0am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keypoints: DKM"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.011208,
          "end_time": "2024-05-01T06:42:22.135246",
          "exception": false,
          "start_time": "2024-05-01T06:42:22.124038",
          "status": "completed"
        },
        "tags": [],
        "id": "FWsf0BNeA0am"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DKMDataset(Dataset):\n",
        "    def __init__(self, fnames1, fnames2, resize_to, device):\n",
        "        self.fnames1 = fnames1\n",
        "        self.fnames2 = fnames2\n",
        "        self.resize_to = resize_to\n",
        "        self.device = device\n",
        "        self.test_transform = get_tuple_transform_ops(\n",
        "            resize=self.resize_to, normalize=True\n",
        "        )\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.fnames1)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname1 = self.fnames1[idx]\n",
        "        fname2 = self.fnames2[idx]\n",
        "\n",
        "        im1, im2 = Image.open(fname1), Image.open(fname2)\n",
        "        ori_shape_1 = im1.size\n",
        "        ori_shape_2 = im2.size\n",
        "        image1, image2 = self.test_transform((im1, im2))\n",
        "        return image1, image2, torch.tensor([idx]), torch.tensor(ori_shape_1), torch.tensor(ori_shape_2)\n",
        "\n",
        "def get_dkm_dataloader(images1, images2, resize_to, device, batch_size=4):\n",
        "    dataset = DKMDataset(images1, images2, resize_to, device)\n",
        "    dataloader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        shuffle=False,\n",
        "        batch_size=batch_size,\n",
        "        pin_memory=True,\n",
        "        num_workers=2,\n",
        "        drop_last=False\n",
        "    )\n",
        "    return dataloader\n",
        "\n",
        "def get_dkm_mkpts(dkm_model, bimgs1, bimgs2, shapes1, shapes2, detection_threshold=0.5, num_features = 2000, min_matches=15):\n",
        "    dense_matches, dense_certainty = dkm_model.match(bimgs1, bimgs2, batched=True)\n",
        "    print(\"***\", dense_matches.shape, dense_certainty.shape)\n",
        "\n",
        "    store_mkpts1, store_mkpts2, store_mconf = [], [], []\n",
        "    # drop low confidence pairs\n",
        "    for b in range(dense_matches.shape[0]):\n",
        "        u_dense_matches = dense_matches[b, dense_certainty[b,...].sqrt() >= detection_threshold, :]\n",
        "        u_dense_certainty = dense_certainty[b, dense_certainty[b,...].sqrt() >= detection_threshold]\n",
        "\n",
        "        if u_dense_matches.shape[0] > num_features:\n",
        "            u_dense_matches, u_dense_certainty = dkm_model.sample( u_dense_matches, u_dense_certainty, num=num_features)\n",
        "\n",
        "        u_dense_matches = u_dense_matches.reshape((-1, 4))\n",
        "        u_dense_certainty = u_dense_certainty.reshape((-1,))\n",
        "\n",
        "        mkpts1 = u_dense_matches[:, :2]\n",
        "        mkpts2 = u_dense_matches[:, 2:]\n",
        "\n",
        "        w1, h1 = shapes1[b, :]\n",
        "        w2, h2 = shapes2[b, :]\n",
        "\n",
        "        mkpts1[:, 0] = ((mkpts1[:, 0] + 1)/2) * w1\n",
        "        mkpts1[:, 1] = ((mkpts1[:, 1] + 1)/2) * h1\n",
        "\n",
        "        mkpts2[:, 0] = ((mkpts2[:, 0] + 1)/2) * w2\n",
        "        mkpts2[:, 1] = ((mkpts2[:, 1] + 1)/2) * h2\n",
        "\n",
        "        mkpts1 = mkpts1.cpu().detach().numpy()\n",
        "        mkpts2 = mkpts2.cpu().detach().numpy()\n",
        "        mconf  = u_dense_certainty.sqrt().cpu().detach().numpy()\n",
        "\n",
        "\n",
        "        if mconf.shape[0] > min_matches:\n",
        "            try:\n",
        "                # calc Fundamental matrix from keypoints\n",
        "                F, inliers = cv2.findFundamentalMat(mkpts1, mkpts2, cv2.USAC_MAGSAC, 0.200, 0.999, 2000)\n",
        "                inliers = inliers > 0\n",
        "                mkpts1 = mkpts1[inliers[:,0]]\n",
        "                mkpts2 = mkpts2[inliers[:,0]]\n",
        "                mconf  = mconf[inliers[:,0]]\n",
        "                #print(\"---\", mconf.shape)\n",
        "                if mconf.shape[0] > 3000:\n",
        "                    rand_idx = np.random.choice(range(mconf.shape[0]), 3000, replace=False)\n",
        "                    mkpts1 = mkpts1[rand_idx, :]\n",
        "                    mkpts2 = mkpts2[rand_idx, :]\n",
        "                    mconf  = mconf[rand_idx]\n",
        "            except:\n",
        "                mkpts1 = np.empty((0,2))\n",
        "                mkpts2 = np.empty((0,2))\n",
        "                mconf = np.empty((0,))\n",
        "\n",
        "        store_mkpts1.append(mkpts1)\n",
        "        store_mkpts2.append(mkpts2)\n",
        "        store_mconf.append(mconf)\n",
        "    return store_mkpts1, store_mkpts2, store_mconf\n",
        "\n",
        "def detect_dkm(\n",
        "    img_fnames, index_pairs, feature_dir, device,\n",
        "    resize_to=(540, 720),\n",
        "    detection_threshold=0.4,\n",
        "    num_features=2000,\n",
        "    min_matches=15,\n",
        "):\n",
        "    t=time()\n",
        "    dkm_model = DKMv3_outdoor(device=device)\n",
        "    dkm_model.upsample_preds=False\n",
        "\n",
        "    fnames1, fnames2 = [], []\n",
        "    for pair_idx in progress_bar(index_pairs):\n",
        "        idx1, idx2 = pair_idx\n",
        "        fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n",
        "        fnames1.append(fname1)\n",
        "        fnames2.append(fname2)\n",
        "\n",
        "    cnt_pairs = 0\n",
        "    with h5py.File(f'{feature_dir}/matches_dkm.h5', mode='w') as f_match:\n",
        "        dataloader = get_dkm_dataloader(fnames1, fnames2, resize_to, device, batch_size=4)\n",
        "        for X in tqdm(dataloader):\n",
        "            images1, images2, idxs, shapes1, shapes2 = X\n",
        "            store_mkpts1, store_mkpts2, store_mconf = get_dkm_mkpts(\n",
        "                dkm_model, images1.to(device), images2.to(device), shapes1, shapes2,\n",
        "                detection_threshold=detection_threshold, num_features = num_features, min_matches=min_matches,\n",
        "            )\n",
        "\n",
        "            for b in range(images1.shape[0]):\n",
        "                mkpts1 = store_mkpts1[b]\n",
        "                mkpts2 = store_mkpts2[b]\n",
        "                mconf = store_mconf[b]\n",
        "                file1 = fnames1[idxs[b]]\n",
        "                file2 = fnames2[idxs[b]]\n",
        "                key1, key2 = file1.split('/')[-1], file2.split('/')[-1]\n",
        "\n",
        "                n_matches = mconf.shape[0]\n",
        "                print (f'{key1}-{key2}: {n_matches} matches @ {cnt_pairs}th pair(dkm)')\n",
        "\n",
        "                group  = f_match.require_group(key1)\n",
        "                if n_matches >= min_matches:\n",
        "                    group.create_dataset(key2, data=np.concatenate([mkpts1, mkpts2], axis=1).astype(np.float32))\n",
        "                    cnt_pairs+=1\n",
        "    gc.collect()\n",
        "    t=time() -t\n",
        "    print(f'Features matched in  {t:.4f} sec')\n",
        "    return t"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "papermill": {
          "duration": 0.042314,
          "end_time": "2024-05-01T06:42:22.188932",
          "exception": false,
          "start_time": "2024-05-01T06:42:22.146618",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-05-14T07:26:37.736635Z",
          "iopub.execute_input": "2024-05-14T07:26:37.736941Z",
          "iopub.status.idle": "2024-05-14T07:26:37.768962Z",
          "shell.execute_reply.started": "2024-05-14T07:26:37.736916Z",
          "shell.execute_reply": "2024-05-14T07:26:37.767982Z"
        },
        "trusted": true,
        "id": "XU9-ctpiA0am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keypoints: LoFTR"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.011262,
          "end_time": "2024-05-01T06:42:22.211625",
          "exception": false,
          "start_time": "2024-05-01T06:42:22.200363",
          "status": "completed"
        },
        "tags": [],
        "id": "xC7-38g1A0am"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LoFTRDataset(Dataset):\n",
        "    def __init__(self, fnames1, fnames2, idxs1, idxs2, resize_small_edge_to, device):\n",
        "        self.fnames1 = fnames1\n",
        "        self.fnames2 = fnames2\n",
        "        self.keys1 = [ fname.split('/')[-1] for fname in fnames1 ]\n",
        "        self.keys2 = [ fname.split('/')[-1] for fname in fnames2 ]\n",
        "        self.idxs1 = idxs1\n",
        "        self.idxs2 = idxs2\n",
        "        self.resize_small_edge_to = resize_small_edge_to\n",
        "        self.device = device\n",
        "        self.round_unit = 16\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images1)\n",
        "\n",
        "    def load_torch_image(self, fname, device):\n",
        "        img = cv2.imread(fname)\n",
        "        original_shape = img.shape\n",
        "        ratio = self.resize_small_edge_to / min([img.shape[0], img.shape[1]])\n",
        "        w = int(img.shape[1] * ratio) # int( (img.shape[1] * ratio) // self.round_unit * self.round_unit )\n",
        "        h = int(img.shape[0] * ratio) # int( (img.shape[0] * ratio) // self.round_unit * self.round_unit )\n",
        "        img_resized = cv2.resize(img, (w, h))\n",
        "        img_resized = K.image_to_tensor(img_resized, False).float() /255.\n",
        "        img_resized = K.color.bgr_to_rgb(img_resized)\n",
        "        img_resized = K.color.rgb_to_grayscale(img_resized)\n",
        "        return img_resized.to(device), original_shape\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname1 = self.fnames1[idx]\n",
        "        fname2 = self.fnames2[idx]\n",
        "        image1, ori_shape_1 = self.load_torch_image(fname1, device)\n",
        "        image2, ori_shape_2 = self.load_torch_image(fname2, device)\n",
        "\n",
        "        return image1, image2, self.keys1[idx], self.keys2[idx], self.idxs1[idx], self.idxs2[idx], ori_shape_1, ori_shape_2\n",
        "\n",
        "def get_loftr_dataloader(images1, images2, idxs1, idxs2, resize_small_edge_to, device, batch_size=1):\n",
        "    dataset = LoFTRDataset(images1, images2, idxs1, idxs2, resize_small_edge_to, device)\n",
        "    dataloader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        shuffle=False,\n",
        "        batch_size=batch_size,\n",
        "        pin_memory=True,\n",
        "        num_workers=2,\n",
        "        drop_last=False\n",
        "    )\n",
        "    return dataset\n",
        "\n",
        "def detect_loftr(img_fnames, index_pairs, feature_dir, device, file_keypoints, resize_small_edge_to=750, min_matches=15):\n",
        "    t=time()\n",
        "\n",
        "    matcher = LoFTR(pretrained=None)\n",
        "    matcher.load_state_dict(torch.load(\"../input/loftr/pytorch/outdoor/1/loftr_outdoor.ckpt\")['state_dict'])\n",
        "    matcher = matcher.to(device).eval()\n",
        "\n",
        "    fnames1, fnames2, idxs1, idxs2 = [], [], [], []\n",
        "    for pair_idx in progress_bar(index_pairs):\n",
        "        idx1, idx2 = pair_idx\n",
        "        fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n",
        "        fnames1.append(fname1)\n",
        "        fnames2.append(fname2)\n",
        "        idxs1.append(idx1)\n",
        "        idxs2.append(idx2)\n",
        "\n",
        "\n",
        "    dataloader = get_loftr_dataloader( fnames1, fnames2, idxs1, idxs2, resize_small_edge_to, device)\n",
        "\n",
        "    cnt_pairs = 0\n",
        "\n",
        "    with h5py.File(file_keypoints, mode='w') as f_match:\n",
        "        store_mkpts = {}\n",
        "        for X in tqdm(dataloader):\n",
        "            image1, image2, key1, key2, idx1, idx2, ori_shape_1, ori_shape_2 = X\n",
        "            fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n",
        "\n",
        "            with torch.no_grad():\n",
        "                correspondences = matcher( {\"image0\": image1.to(device),\"image1\": image2.to(device)} )\n",
        "                mkpts1 = correspondences['keypoints0'].cpu().numpy()\n",
        "                mkpts2 = correspondences['keypoints1'].cpu().numpy()\n",
        "                mconf  = correspondences['confidence'].cpu().numpy()\n",
        "\n",
        "            mkpts1[:,0] *= (float(ori_shape_1[1]) / float(image1.shape[3]))\n",
        "            mkpts1[:,1] *= (float(ori_shape_1[0]) / float(image1.shape[2]))\n",
        "\n",
        "            mkpts2[:,0] *= (float(ori_shape_2[1]) / float(image2.shape[3]))\n",
        "            mkpts2[:,1] *= (float(ori_shape_2[0]) / float(image2.shape[2]))\n",
        "\n",
        "            n_matches = mconf.shape[0]\n",
        "\n",
        "            group  = f_match.require_group(key1)\n",
        "            if n_matches >= min_matches:\n",
        "                group.create_dataset(key2, data=np.concatenate([mkpts1, mkpts2], axis=1).astype(np.float32))\n",
        "                cnt_pairs+=1\n",
        "                print (f'{key1}-{key2}: {n_matches} matches @ {cnt_pairs}th pair(loftr)')\n",
        "            else:\n",
        "                print (f'{key1}-{key2}: {n_matches} matches --> skipped')\n",
        "    gc.collect()\n",
        "    t=time() -t\n",
        "    print(f'Features matched in  {t:.4f} sec')\n",
        "    return t"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "papermill": {
          "duration": 0.036571,
          "end_time": "2024-05-01T06:42:22.259539",
          "exception": false,
          "start_time": "2024-05-01T06:42:22.222968",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-05-14T07:26:37.770423Z",
          "iopub.execute_input": "2024-05-14T07:26:37.770965Z",
          "iopub.status.idle": "2024-05-14T07:26:37.796466Z",
          "shell.execute_reply.started": "2024-05-14T07:26:37.770928Z",
          "shell.execute_reply": "2024-05-14T07:26:37.795546Z"
        },
        "trusted": true,
        "id": "6s4jiF6cA0ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keypoints: DKM"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.011363,
          "end_time": "2024-05-01T06:42:22.282325",
          "exception": false,
          "start_time": "2024-05-01T06:42:22.270962",
          "status": "completed"
        },
        "tags": [],
        "id": "wCNKd6lsA0ao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DKMDataset(Dataset):\n",
        "    def __init__(self, fnames1, fnames2, resize_to, device):\n",
        "        self.fnames1 = fnames1\n",
        "        self.fnames2 = fnames2\n",
        "        self.resize_to = resize_to\n",
        "        self.device = device\n",
        "        self.test_transform = get_tuple_transform_ops(\n",
        "            resize=self.resize_to, normalize=True\n",
        "        )\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.fnames1)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname1 = self.fnames1[idx]\n",
        "        fname2 = self.fnames2[idx]\n",
        "\n",
        "        im1, im2 = Image.open(fname1), Image.open(fname2)\n",
        "        ori_shape_1 = im1.size\n",
        "        ori_shape_2 = im2.size\n",
        "        image1, image2 = self.test_transform((im1, im2))\n",
        "        return image1, image2, torch.tensor([idx]), torch.tensor(ori_shape_1), torch.tensor(ori_shape_2)\n",
        "\n",
        "def get_dkm_dataloader(images1, images2, resize_to, device, batch_size=4):\n",
        "    dataset = DKMDataset(images1, images2, resize_to, device)\n",
        "    dataloader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        shuffle=False,\n",
        "        batch_size=batch_size,\n",
        "        pin_memory=True,\n",
        "        num_workers=2,\n",
        "        drop_last=False\n",
        "    )\n",
        "    return dataloader\n",
        "\n",
        "def get_dkm_mkpts(dkm_model, bimgs1, bimgs2, shapes1, shapes2, detection_threshold=0.5, num_features = 2000, min_matches=15):\n",
        "    dense_matches, dense_certainty = dkm_model.match(bimgs1, bimgs2, batched=True)\n",
        "\n",
        "    store_mkpts1, store_mkpts2, store_mconf = [], [], []\n",
        "    # drop low confidence pairs\n",
        "    for b in range(dense_matches.shape[0]):\n",
        "        u_dense_matches = dense_matches[b, dense_certainty[b,...].sqrt() >= detection_threshold, :]\n",
        "        u_dense_certainty = dense_certainty[b, dense_certainty[b,...].sqrt() >= detection_threshold]\n",
        "\n",
        "        if u_dense_matches.shape[0] > num_features:\n",
        "            u_dense_matches, u_dense_certainty = dkm_model.sample( u_dense_matches, u_dense_certainty, num=num_features)\n",
        "\n",
        "        u_dense_matches = u_dense_matches.reshape((-1, 4))\n",
        "        u_dense_certainty = u_dense_certainty.reshape((-1,))\n",
        "\n",
        "        mkpts1 = u_dense_matches[:, :2]\n",
        "        mkpts2 = u_dense_matches[:, 2:]\n",
        "\n",
        "        w1, h1 = shapes1[b, :]\n",
        "        w2, h2 = shapes2[b, :]\n",
        "\n",
        "        mkpts1[:, 0] = ((mkpts1[:, 0] + 1)/2) * w1\n",
        "        mkpts1[:, 1] = ((mkpts1[:, 1] + 1)/2) * h1\n",
        "\n",
        "        mkpts2[:, 0] = ((mkpts2[:, 0] + 1)/2) * w2\n",
        "        mkpts2[:, 1] = ((mkpts2[:, 1] + 1)/2) * h2\n",
        "\n",
        "        mkpts1 = mkpts1.cpu().detach().numpy()\n",
        "        mkpts2 = mkpts2.cpu().detach().numpy()\n",
        "        mconf  = u_dense_certainty.sqrt().cpu().detach().numpy()\n",
        "\n",
        "        if mconf.shape[0] > min_matches:\n",
        "            try:\n",
        "                # calc Fundamental matrix from keypoints\n",
        "                F, inliers = cv2.findFundamentalMat(mkpts1, mkpts2, cv2.USAC_MAGSAC, 0.200, 0.999, 2000)\n",
        "                inliers = inliers > 0\n",
        "                mkpts1 = mkpts1[inliers[:,0]]\n",
        "                mkpts2 = mkpts2[inliers[:,0]]\n",
        "                mconf  = mconf[inliers[:,0]]\n",
        "            except:\n",
        "                pass\n",
        "        store_mkpts1.append(mkpts1)\n",
        "        store_mkpts2.append(mkpts2)\n",
        "        store_mconf.append(mconf)\n",
        "    return store_mkpts1, store_mkpts2, store_mconf\n",
        "\n",
        "def detect_dkm(\n",
        "    img_fnames, index_pairs, feature_dir, device, file_keypoints,\n",
        "    resize_to=(540, 720),\n",
        "    detection_threshold=0.4,\n",
        "    num_features=2000,\n",
        "    min_matches=15\n",
        "):\n",
        "    t=time()\n",
        "    dkm_model = DKMv3_outdoor(device=device)\n",
        "    dkm_model.upsample_preds=False\n",
        "\n",
        "    fnames1, fnames2 = [], []\n",
        "    for pair_idx in progress_bar(index_pairs):\n",
        "        idx1, idx2 = pair_idx\n",
        "        fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n",
        "        fnames1.append(fname1)\n",
        "        fnames2.append(fname2)\n",
        "\n",
        "    cnt_pairs = 0\n",
        "    with h5py.File(file_keypoints, mode='w') as f_match:\n",
        "        dataloader = get_dkm_dataloader(fnames1, fnames2, resize_to, device, batch_size=4)\n",
        "        for X in tqdm(dataloader):\n",
        "            images1, images2, idxs, shapes1, shapes2 = X\n",
        "            store_mkpts1, store_mkpts2, store_mconf = get_dkm_mkpts(\n",
        "                dkm_model, images1.to(device), images2.to(device), shapes1, shapes2,\n",
        "                detection_threshold=detection_threshold, num_features = num_features, min_matches=min_matches,\n",
        "            )\n",
        "\n",
        "            for b in range(images1.shape[0]):\n",
        "                mkpts1 = store_mkpts1[b]\n",
        "                mkpts2 = store_mkpts2[b]\n",
        "                mconf = store_mconf[b]\n",
        "                file1 = fnames1[idxs[b]]\n",
        "                file2 = fnames2[idxs[b]]\n",
        "                key1, key2 = file1.split('/')[-1], file2.split('/')[-1]\n",
        "\n",
        "                n_matches = mconf.shape[0]\n",
        "\n",
        "                group  = f_match.require_group(key1)\n",
        "                if n_matches >= min_matches:\n",
        "                    group.create_dataset(key2, data=np.concatenate([mkpts1, mkpts2], axis=1).astype(np.float32))\n",
        "                    cnt_pairs+=1\n",
        "                    print (f'{key1}-{key2}: {n_matches} matches @ {cnt_pairs}th pair(dkm)')\n",
        "                else:\n",
        "                    print (f'{key1}-{key2}: {n_matches} matches --> skipped')\n",
        "\n",
        "    gc.collect()\n",
        "    t=time() -t\n",
        "    print(f'Features matched in  {t:.4f} sec')\n",
        "    return t"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "papermill": {
          "duration": 0.040559,
          "end_time": "2024-05-01T06:42:22.334304",
          "exception": false,
          "start_time": "2024-05-01T06:42:22.293745",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-05-14T07:26:37.797858Z",
          "iopub.execute_input": "2024-05-14T07:26:37.798155Z",
          "iopub.status.idle": "2024-05-14T07:26:37.827294Z",
          "shell.execute_reply.started": "2024-05-14T07:26:37.798124Z",
          "shell.execute_reply": "2024-05-14T07:26:37.826365Z"
        },
        "trusted": true,
        "id": "zDuhgmV9A0ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keypoints merger"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.011144,
          "end_time": "2024-05-01T06:42:22.357093",
          "exception": false,
          "start_time": "2024-05-01T06:42:22.345949",
          "status": "completed"
        },
        "tags": [],
        "id": "e6S5Vt8SA0ap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unique_idxs(A, dim=0):\n",
        "    # https://stackoverflow.com/questions/72001505/how-to-get-unique-elements-and-their-firstly-appeared-indices-of-a-pytorch-tenso\n",
        "    unique, idx, counts = torch.unique(A, dim=dim, sorted=True, return_inverse=True, return_counts=True)\n",
        "    _, ind_sorted = torch.sort(idx, stable=True)\n",
        "    cum_sum = counts.cumsum(0)\n",
        "    cum_sum = torch.cat((torch.tensor([0],device=cum_sum.device), cum_sum[:-1]))\n",
        "    first_indices = ind_sorted[cum_sum]\n",
        "    return first_indices\n",
        "\n",
        "def get_keypoint_from_h5(fp, key1, key2):\n",
        "    rc = -1\n",
        "    try:\n",
        "        kpts = np.array(fp[key1][key2])\n",
        "        rc = 0\n",
        "        return (rc, kpts)\n",
        "    except:\n",
        "        return (rc, None)\n",
        "\n",
        "def get_keypoint_from_multi_h5(fps, key1, key2):\n",
        "    list_mkpts = []\n",
        "    for fp in fps:\n",
        "        rc, mkpts = get_keypoint_from_h5(fp, key1, key2)\n",
        "        if rc == 0:\n",
        "            list_mkpts.append(mkpts)\n",
        "    if len(list_mkpts) > 0:\n",
        "        list_mkpts = np.concatenate(list_mkpts, axis=0)\n",
        "    else:\n",
        "        list_mkpts = None\n",
        "    return list_mkpts\n",
        "\n",
        "def keypoints_merger(\n",
        "    img_fnames,\n",
        "    index_pairs,\n",
        "    files_keypoints,\n",
        "    feature_dir = 'featureout',\n",
        "):\n",
        "    # open h5 files\n",
        "    fps = [ h5py.File(file, mode=\"r\") for file in files_keypoints ]\n",
        "\n",
        "    # temprary file\n",
        "    with h5py.File(f'{feature_dir}/merge_tmp.h5', mode='w') as f_match:\n",
        "        counter = 0\n",
        "        for pair_idx in progress_bar(index_pairs):\n",
        "            idx1, idx2 = pair_idx\n",
        "            fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n",
        "            key1, key2 = fname1.split('/')[-1], fname2.split('/')[-1]\n",
        "\n",
        "            # extract keypoints\n",
        "            mkpts = get_keypoint_from_multi_h5(fps, key1, key2)\n",
        "            if mkpts is None:\n",
        "                print(f\"skipped key1={key1}, key2={key2}\")\n",
        "                continue\n",
        "\n",
        "            print (f'{key1}-{key2}: {mkpts.shape[0]} matches')\n",
        "            # regist tmp file\n",
        "            group  = f_match.require_group(key1)\n",
        "            group.create_dataset(key2, data=mkpts)\n",
        "            counter += 1\n",
        "    print( f\"Ensembled pairs : {counter} pairs\" )\n",
        "    for fp in fps:\n",
        "        fp.close()\n",
        "\n",
        "    # Let's find unique loftr pixels and group them together.\n",
        "    kpts = defaultdict(list)\n",
        "    match_indexes = defaultdict(dict)\n",
        "    total_kpts=defaultdict(int)\n",
        "    with h5py.File(f'{feature_dir}/merge_tmp.h5', mode='r') as f_match:\n",
        "        for k1 in f_match.keys():\n",
        "            group  = f_match[k1]\n",
        "            for k2 in group.keys():\n",
        "                matches = group[k2][...]\n",
        "                total_kpts[k1]\n",
        "                kpts[k1].append(matches[:, :2])\n",
        "                kpts[k2].append(matches[:, 2:])\n",
        "                current_match = torch.arange(len(matches)).reshape(-1, 1).repeat(1, 2)\n",
        "                current_match[:, 0]+=total_kpts[k1]\n",
        "                current_match[:, 1]+=total_kpts[k2]\n",
        "                total_kpts[k1]+=len(matches)\n",
        "                total_kpts[k2]+=len(matches)\n",
        "                match_indexes[k1][k2]=current_match\n",
        "\n",
        "    for k in kpts.keys():\n",
        "        kpts[k] = np.round(np.concatenate(kpts[k], axis=0))\n",
        "    unique_kpts = {}\n",
        "    unique_match_idxs = {}\n",
        "    out_match = defaultdict(dict)\n",
        "    for k in kpts.keys():\n",
        "        uniq_kps, uniq_reverse_idxs = torch.unique(torch.from_numpy(kpts[k]),dim=0, return_inverse=True)\n",
        "        unique_match_idxs[k] = uniq_reverse_idxs\n",
        "        unique_kpts[k] = uniq_kps.numpy()\n",
        "    for k1, group in match_indexes.items():\n",
        "        for k2, m in group.items():\n",
        "            m2 = deepcopy(m)\n",
        "            m2[:,0] = unique_match_idxs[k1][m2[:,0]]\n",
        "            m2[:,1] = unique_match_idxs[k2][m2[:,1]]\n",
        "            mkpts = np.concatenate([unique_kpts[k1][ m2[:,0]],\n",
        "                                    unique_kpts[k2][  m2[:,1]],\n",
        "                                   ],\n",
        "                                   axis=1)\n",
        "            unique_idxs_current = get_unique_idxs(torch.from_numpy(mkpts), dim=0)\n",
        "            m2_semiclean = m2[unique_idxs_current]\n",
        "            unique_idxs_current1 = get_unique_idxs(m2_semiclean[:, 0], dim=0)\n",
        "            m2_semiclean = m2_semiclean[unique_idxs_current1]\n",
        "            unique_idxs_current2 = get_unique_idxs(m2_semiclean[:, 1], dim=0)\n",
        "            m2_semiclean2 = m2_semiclean[unique_idxs_current2]\n",
        "            out_match[k1][k2] = m2_semiclean2.numpy()\n",
        "    with h5py.File(f'{feature_dir}/keypoints.h5', mode='w') as f_kp:\n",
        "        for k, kpts1 in unique_kpts.items():\n",
        "            f_kp[k] = kpts1\n",
        "\n",
        "    with h5py.File(f'{feature_dir}/matches.h5', mode='w') as f_match:\n",
        "        for k1, gr in out_match.items():\n",
        "            group  = f_match.require_group(k1)\n",
        "            for k2, match in gr.items():\n",
        "                group[k2] = match\n",
        "    return"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "papermill": {
          "duration": 0.038951,
          "end_time": "2024-05-01T06:42:22.407395",
          "exception": false,
          "start_time": "2024-05-01T06:42:22.368444",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-05-14T07:26:37.828987Z",
          "iopub.execute_input": "2024-05-14T07:26:37.829361Z",
          "iopub.status.idle": "2024-05-14T07:26:37.856848Z",
          "shell.execute_reply.started": "2024-05-14T07:26:37.829327Z",
          "shell.execute_reply": "2024-05-14T07:26:37.855858Z"
        },
        "trusted": true,
        "id": "eiWeo9UFA0ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission utilities"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.011212,
          "end_time": "2024-05-01T06:42:22.430214",
          "exception": false,
          "start_time": "2024-05-01T06:42:22.419002",
          "status": "completed"
        },
        "tags": [],
        "id": "Mgl2TsL7A0ap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def arr_to_str(a):\n",
        "    return ';'.join([str(x) for x in a.reshape(-1)])\n",
        "\n",
        "# Function to create a submission file.\n",
        "def create_submission(out_results, data_dict):\n",
        "    with open(f'submission.csv', 'w') as f:\n",
        "        f.write('image_path,dataset,scene,rotation_matrix,translation_vector\\n')\n",
        "        for dataset in data_dict:\n",
        "            if dataset in out_results:\n",
        "                res = out_results[dataset]\n",
        "            else:\n",
        "                res = {}\n",
        "            for scene in data_dict[dataset]:\n",
        "                if scene in res:\n",
        "                    scene_res = res[scene]\n",
        "                else:\n",
        "                    scene_res = {\"R\":{}, \"t\":{}}\n",
        "                for image in data_dict[dataset][scene]:\n",
        "                    if image in scene_res:\n",
        "                        print (image)\n",
        "                        R = scene_res[image]['R'].reshape(-1)\n",
        "                        T = scene_res[image]['t'].reshape(-1)\n",
        "                    else:\n",
        "                        R = np.eye(3).reshape(-1)\n",
        "                        T = np.zeros((3))\n",
        "                    f.write(f'{image},{dataset},{scene},{arr_to_str(R)},{arr_to_str(T)}\\n')"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.022598,
          "end_time": "2024-05-01T06:42:22.464305",
          "exception": false,
          "start_time": "2024-05-01T06:42:22.441707",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-05-14T07:26:37.858005Z",
          "iopub.execute_input": "2024-05-14T07:26:37.858323Z",
          "iopub.status.idle": "2024-05-14T07:26:37.871804Z",
          "shell.execute_reply.started": "2024-05-14T07:26:37.858296Z",
          "shell.execute_reply": "2024-05-14T07:26:37.870847Z"
        },
        "trusted": true,
        "id": "k1O9eE8bA0ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.011266,
          "end_time": "2024-05-01T06:42:22.487208",
          "exception": false,
          "start_time": "2024-05-01T06:42:22.475942",
          "status": "completed"
        },
        "tags": [],
        "id": "I8HPfewVA0ap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src = '/kaggle/input/image-matching-challenge-2024'\n",
        "DEBUG = False\n",
        "DUMP = False\n",
        "\n",
        "# Get data from csv.\n",
        "data_dict = {}\n",
        "with open(f'{src}/sample_submission.csv', 'r') as f:\n",
        "    for i, l in enumerate(f):\n",
        "        # Skip header.\n",
        "        if l and i > 0:\n",
        "            image, dataset, scene, _, _ = l.strip().split(',')\n",
        "            if dataset not in data_dict:\n",
        "                data_dict[dataset] = {}\n",
        "            if scene not in data_dict[dataset]:\n",
        "                data_dict[dataset][scene] = []\n",
        "            data_dict[dataset][scene].append(image)\n",
        "\n",
        "            #if len(data_dict[dataset][scene]) == 21:\n",
        "            #    break"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.027161,
          "end_time": "2024-05-01T06:42:22.525884",
          "exception": false,
          "start_time": "2024-05-01T06:42:22.498723",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-05-14T07:26:37.873173Z",
          "iopub.execute_input": "2024-05-14T07:26:37.873614Z",
          "iopub.status.idle": "2024-05-14T07:26:37.888332Z",
          "shell.execute_reply.started": "2024-05-14T07:26:37.873576Z",
          "shell.execute_reply": "2024-05-14T07:26:37.887279Z"
        },
        "trusted": true,
        "id": "KCh4aOhUA0aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset in data_dict:\n",
        "    for scene in data_dict[dataset]:\n",
        "        print(f'{dataset} / {scene} -> {len(data_dict[dataset][scene])} images')"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.019031,
          "end_time": "2024-05-01T06:42:22.5569",
          "exception": false,
          "start_time": "2024-05-01T06:42:22.537869",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-05-14T07:26:37.889746Z",
          "iopub.execute_input": "2024-05-14T07:26:37.890198Z",
          "iopub.status.idle": "2024-05-14T07:26:37.895804Z",
          "shell.execute_reply.started": "2024-05-14T07:26:37.890163Z",
          "shell.execute_reply": "2024-05-14T07:26:37.894732Z"
        },
        "trusted": true,
        "id": "Wk_EqacCA0aq",
        "outputId": "a8e7f7a6-4b28-4e8c-9278-70b2b3840050"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "church / church -> 41 images\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_results = {}\n",
        "timings = {\"shortlisting\":[],\n",
        "           \"feature_detection\": [],\n",
        "           \"feature_matching\":[],\n",
        "           \"RANSAC\": [],\n",
        "           \"Reconstruction\": []}"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.018485,
          "end_time": "2024-05-01T06:42:22.58687",
          "exception": false,
          "start_time": "2024-05-01T06:42:22.568385",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-05-14T07:26:37.897027Z",
          "iopub.execute_input": "2024-05-14T07:26:37.897434Z",
          "iopub.status.idle": "2024-05-14T07:26:37.905634Z",
          "shell.execute_reply.started": "2024-05-14T07:26:37.897408Z",
          "shell.execute_reply": "2024-05-14T07:26:37.904484Z"
        },
        "trusted": true,
        "id": "zeTl2OW8A0aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()\n",
        "datasets = []\n",
        "for dataset in data_dict:\n",
        "    datasets.append(dataset)\n",
        "\n",
        "for dataset in datasets:\n",
        "    print(dataset)\n",
        "    if dataset not in out_results:\n",
        "        out_results[dataset] = {}\n",
        "    for scene in data_dict[dataset]:\n",
        "        print(scene)\n",
        "        # Fail gently if the notebook has not been submitted and the test data is not populated.\n",
        "        # You may want to run this on the training data in that case?\n",
        "        img_dir = f'{src}/test/{dataset}/images'\n",
        "        if not os.path.exists(img_dir):\n",
        "            continue\n",
        "        # Wrap the meaty part in a try-except block.\n",
        "        try:\n",
        "            out_results[dataset][scene] = {}\n",
        "            img_fnames = [f'{src}/{x}' for x in data_dict[dataset][scene]]\n",
        "            print (f\"Got {len(img_fnames)} images\")\n",
        "            feature_dir = f'featureout/{dataset}_{scene}'\n",
        "            if not os.path.isdir(feature_dir):\n",
        "                os.makedirs(feature_dir, exist_ok=True)\n",
        "\n",
        "            #############################################################\n",
        "            # get image pairs\n",
        "            #############################################################\n",
        "            t=time()\n",
        "            index_pairs = get_image_pairs_shortlist(img_fnames,\n",
        "                                  sim_th = 1.0, # should be strict\n",
        "                                  min_pairs = 50, # we select at least min_pairs PER IMAGE with biggest similarity\n",
        "                                  exhaustive_if_less = 50,\n",
        "                                  device=device)\n",
        "            t=time() -t\n",
        "            timings['shortlisting'].append(t)\n",
        "            print (f'{len(index_pairs)}, pairs to match, {t:.4f} sec')\n",
        "            gc.collect()\n",
        "\n",
        "            #############################################################\n",
        "            # get keypoints\n",
        "            #############################################################\n",
        "            files_keypoints = []\n",
        "            if CONFIG.use_superglue:\n",
        "                resize_to = CONFIG.params_sg[\"resize_to\"]\n",
        "                file_keypoints = f\"{feature_dir}/matches_superglue_{resize_to}pix.h5\"\n",
        "                !rm -rf {file_keypoints}\n",
        "                t = detect_superglue(\n",
        "                    img_fnames, index_pairs, feature_dir, device,\n",
        "                    CONFIG.params_sg[\"sg_config\"], file_keypoints,\n",
        "                    resize_to=CONFIG.params_sg[\"resize_to\"],\n",
        "                    min_matches=CONFIG.params_sg[\"min_matches\"],\n",
        "                )\n",
        "                gc.collect()\n",
        "                files_keypoints.append( file_keypoints )\n",
        "                timings['feature_matching'].append(t)\n",
        "\n",
        "            if CONFIG.use_aliked_lightglue:\n",
        "                model_name = \"aliked\"\n",
        "                file_keypoints = f'{feature_dir}/matches_lightglue_{model_name}.h5'\n",
        "                t = detect_lightglue_common(\n",
        "                    img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints,\n",
        "                    resize_to=CONFIG.params_aliked_lightglue[\"resize_to\"],\n",
        "                    detection_threshold=CONFIG.params_aliked_lightglue[\"detection_threshold\"],\n",
        "                    num_features=CONFIG.params_aliked_lightglue[\"num_features\"],\n",
        "                    min_matches=CONFIG.params_aliked_lightglue[\"min_matches\"],\n",
        "                )\n",
        "                gc.collect()\n",
        "                files_keypoints.append(file_keypoints)\n",
        "                timings['feature_matching'].append(t)\n",
        "\n",
        "            if CONFIG.use_doghardnet_lightglue:\n",
        "                model_name = \"doghardnet\"\n",
        "                file_keypoints = f'{feature_dir}/matches_lightglue_{model_name}.h5'\n",
        "                t = detect_lightglue_common(\n",
        "                    img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints,\n",
        "                    resize_to=CONFIG.params_doghardnet_lightglue[\"resize_to\"],\n",
        "                    detection_threshold=CONFIG.params_doghardnet_lightglue[\"detection_threshold\"],\n",
        "                    num_features=CONFIG.params_doghardnet_lightglue[\"num_features\"],\n",
        "                    min_matches=CONFIG.params_doghardnet_lightglue[\"min_matches\"],\n",
        "                )\n",
        "                gc.collect()\n",
        "                files_keypoints.append(file_keypoints)\n",
        "                timings['feature_matching'].append(t)\n",
        "\n",
        "            if CONFIG.use_superpoint_lightglue:\n",
        "                model_name = \"superpoint\"\n",
        "                file_keypoints = f'{feature_dir}/matches_lightglue_{model_name}.h5'\n",
        "                t = detect_lightglue_common(\n",
        "                    img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints,\n",
        "                    resize_to=CONFIG.params_superpoint_lightglue[\"resize_to\"],\n",
        "                    detection_threshold=CONFIG.params_superpoint_lightglue[\"detection_threshold\"],\n",
        "                    num_features=CONFIG.params_superpoint_lightglue[\"num_features\"],\n",
        "                    min_matches=CONFIG.params_superpoint_lightglue[\"min_matches\"],\n",
        "                )\n",
        "                gc.collect()\n",
        "                files_keypoints.append(file_keypoints)\n",
        "                timings['feature_matching'].append(t)\n",
        "\n",
        "            if CONFIG.use_loftr:\n",
        "                file_keypoints = f'{feature_dir}/matches_loftr_{CONFIG.params_loftr[\"resize_small_edge_to\"]}pix.h5'\n",
        "                t = detect_loftr(\n",
        "                    img_fnames, index_pairs, feature_dir, device, file_keypoints,\n",
        "                    resize_small_edge_to=CONFIG.params_loftr[\"resize_small_edge_to\"],\n",
        "                    min_matches=CONFIG.params_loftr[\"min_matches\"],\n",
        "                )\n",
        "                gc.collect()\n",
        "                files_keypoints.append( file_keypoints )\n",
        "                timings['feature_matching'].append(t)\n",
        "\n",
        "            if CONFIG.use_dkm:\n",
        "                file_keypoints = f'{feature_dir}/matches_dkm.h5'\n",
        "                t = detect_dkm(\n",
        "                    img_fnames, index_pairs, feature_dir, device, file_keypoints,\n",
        "                    resize_to=CONFIG.params_dkm[\"resize_to\"],\n",
        "                    detection_threshold=CONFIG.params_dkm[\"detection_threshold\"],\n",
        "                    num_features=CONFIG.params_dkm[\"num_features\"],\n",
        "                    min_matches=CONFIG.params_dkm[\"min_matches\"]\n",
        "                )\n",
        "                gc.collect()\n",
        "                files_keypoints.append(file_keypoints)\n",
        "                timings['feature_matching'].append(t)\n",
        "\n",
        "            #############################################################\n",
        "            # merge keypoints\n",
        "            #############################################################\n",
        "            keypoints_merger(\n",
        "                img_fnames,\n",
        "                index_pairs,\n",
        "                files_keypoints,\n",
        "                feature_dir = feature_dir,\n",
        "            )\n",
        "\n",
        "            #############################################################\n",
        "            # regist keypoints from h5 into colmap db\n",
        "            #############################################################\n",
        "            database_path = f'{feature_dir}/colmap.db'\n",
        "            if os.path.isfile(database_path):\n",
        "                os.remove(database_path)\n",
        "            gc.collect()\n",
        "            import_into_colmap(img_dir, feature_dir=feature_dir,database_path=database_path)\n",
        "            output_path = f'{feature_dir}/colmap_rec'\n",
        "\n",
        "            #############################################################\n",
        "            # Calculate fundamental matrix with colmap api\n",
        "            #############################################################\n",
        "            t=time()\n",
        "            options = pycolmap.SiftMatchingOptions()\n",
        "            options.confidence = 0.9999\n",
        "            options.max_num_trials = 20000\n",
        "            pycolmap.match_exhaustive(database_path, sift_options=options)\n",
        "            t=time() - t\n",
        "            timings['RANSAC'].append(t)\n",
        "            print(f'RANSAC in  {t:.4f} sec')\n",
        "\n",
        "            #############################################################\n",
        "            # Execute bundle adjustmnet with colmap api\n",
        "            # --> Bundle adjustment Calcs Camera matrix, R and t\n",
        "            #############################################################\n",
        "            t=time()\n",
        "            # By default colmap does not generate a reconstruction if less than 10 images are registered. Lower it to 3.\n",
        "            mapper_options = pycolmap.IncrementalMapperOptions()\n",
        "            mapper_options.min_model_size = 3\n",
        "            os.makedirs(output_path, exist_ok=True)\n",
        "            maps = pycolmap.incremental_mapping(database_path=database_path, image_path=img_dir, output_path=output_path, options=mapper_options)\n",
        "            print(maps)\n",
        "            clear_output(wait=False)\n",
        "            t=time() - t\n",
        "            timings['Reconstruction'].append(t)\n",
        "            print(f'Reconstruction done in  {t:.4f} sec')\n",
        "\n",
        "            #############################################################\n",
        "            # Extract R,t from maps\n",
        "            #############################################################\n",
        "            imgs_registered  = 0\n",
        "            best_idx = None\n",
        "            list_num_images = []\n",
        "            print (\"Looking for the best reconstruction\")\n",
        "            if isinstance(maps, dict):\n",
        "                for idx1, rec in maps.items():\n",
        "                    print (idx1, rec.summary())\n",
        "                    list_num_images.append( len(rec.images) )\n",
        "                    if len(rec.images) > imgs_registered:\n",
        "                        imgs_registered = len(rec.images)\n",
        "                        best_idx = idx1\n",
        "            list_num_images = np.array(list_num_images)\n",
        "            print(f\"list_num_images = {list_num_images}\")\n",
        "            if best_idx is not None:\n",
        "                print (maps[best_idx].summary())\n",
        "                for k, im in maps[best_idx].images.items():\n",
        "                    key1 = f'test/{dataset}/images/{im.name}'\n",
        "                    out_results[dataset][scene][key1] = {}\n",
        "                    out_results[dataset][scene][key1][\"R\"] = deepcopy(im.rotmat())\n",
        "                    out_results[dataset][scene][key1][\"t\"] = deepcopy(np.array(im.tvec))\n",
        "\n",
        "            print(f'Registered: {dataset} / {scene} -> {len(out_results[dataset][scene])} images')\n",
        "            print(f'Total: {dataset} / {scene} -> {len(data_dict[dataset][scene])} images')\n",
        "            create_submission(out_results, data_dict)\n",
        "            gc.collect()\n",
        "        except:\n",
        "            pass"
      ],
      "metadata": {
        "papermill": {
          "duration": 979.131014,
          "end_time": "2024-05-01T06:58:41.729323",
          "exception": false,
          "start_time": "2024-05-01T06:42:22.598309",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-05-14T07:26:37.90708Z",
          "iopub.execute_input": "2024-05-14T07:26:37.907346Z"
        },
        "trusted": true,
        "id": "CntBhF5wA0aq",
        "outputId": "638f4359-d4a4-4879-9137-1bd085fb0494"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "church\nchurch\nGot 41 images\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:05<00:00,  7.35it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:03<00:00, 10.32it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "820, pairs to match, 14.1369 sec\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  7%|‚ñã         | 3/41 [00:00<00:06,  5.99it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "aliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 17%|‚ñà‚ñã        | 7/41 [00:00<00:03, 10.92it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "aliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 27%|‚ñà‚ñà‚ñã       | 11/41 [00:01<00:02, 13.17it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "aliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 37%|‚ñà‚ñà‚ñà‚ñã      | 15/41 [00:01<00:01, 14.30it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "aliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 19/41 [00:01<00:01, 14.98it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "aliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 23/41 [00:01<00:01, 14.55it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "aliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 27/41 [00:02<00:00, 14.23it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "aliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 31/41 [00:02<00:00, 14.98it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "aliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 35/41 [00:02<00:00, 15.25it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "aliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 39/41 [00:02<00:00, 15.55it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "aliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:03<00:00, 13.32it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "aliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\naliked > kpts.shape=(8192, 2), descs.shape=(8192, 128)\nLoaded LightGlue model\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  0%|          | 1/820 [00:00<11:49,  1.15it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00069.png-00066.png: 6664 matches @ 1th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  0%|          | 2/820 [00:01<10:34,  1.29it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00030.png-00026.png: 4177 matches @ 2th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  0%|          | 3/820 [00:02<10:10,  1.34it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00030.png-00111.png: 2379 matches @ 3th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  0%|          | 4/820 [00:03<09:58,  1.36it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00066.png-00076.png: 3428 matches @ 4th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  1%|          | 5/820 [00:03<09:50,  1.38it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00069.png-00076.png: 3340 matches @ 5th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  1%|          | 6/820 [00:04<09:47,  1.39it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00068.png-00026.png: 134 matches @ 6th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  1%|          | 7/820 [00:05<09:43,  1.39it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00069.png-00074.png: 2534 matches @ 7th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  1%|          | 8/820 [00:05<09:41,  1.40it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00059.png-00111.png: 79 matches @ 8th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  1%|          | 9/820 [00:06<09:40,  1.40it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00092.png-00087.png: 4079 matches @ 9th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  1%|          | 10/820 [00:07<09:39,  1.40it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00068.png-00030.png: 133 matches @ 10th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  1%|‚ñè         | 11/820 [00:07<09:36,  1.40it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00026.png-00072.png: 149 matches @ 11th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  1%|‚ñè         | 12/820 [00:08<09:34,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00066.png-00074.png: 2522 matches @ 12th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  2%|‚ñè         | 13/820 [00:09<09:34,  1.40it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00026.png-00111.png: 982 matches @ 13th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  2%|‚ñè         | 14/820 [00:10<09:34,  1.40it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00068.png-00072.png: 4037 matches @ 14th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  2%|‚ñè         | 15/820 [00:10<09:33,  1.40it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00030.png-00072.png: 363 matches @ 15th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  2%|‚ñè         | 16/820 [00:11<09:32,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00066.png-00061.png: 440 matches @ 16th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  2%|‚ñè         | 17/820 [00:12<09:30,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00021.png-00039.png: 1505 matches @ 17th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  2%|‚ñè         | 18/820 [00:12<09:30,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00069.png-00061.png: 475 matches @ 18th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  2%|‚ñè         | 19/820 [00:13<09:29,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00032.png-00021.png: 2218 matches @ 19th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  2%|‚ñè         | 20/820 [00:14<09:29,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00006.png-00001.png: 2638 matches @ 20th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  3%|‚ñé         | 21/820 [00:15<09:27,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00035.png-00039.png: 2384 matches @ 21th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  3%|‚ñé         | 22/820 [00:15<09:27,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00032.png-00029.png: 4057 matches @ 22th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  3%|‚ñé         | 23/820 [00:16<09:25,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00011.png-00029.png: 2149 matches @ 23th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  3%|‚ñé         | 24/820 [00:17<09:25,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00013.png-00012.png: 2937 matches @ 24th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  3%|‚ñé         | 25/820 [00:17<09:24,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00026.png-00008.png: 2321 matches @ 25th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  3%|‚ñé         | 26/820 [00:18<09:24,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00030.png-00059.png: 138 matches @ 26th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  3%|‚ñé         | 27/820 [00:19<09:24,  1.40it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00030.png-00029.png: 1668 matches @ 27th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  3%|‚ñé         | 28/820 [00:20<09:24,  1.40it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00008.png-00029.png: 4513 matches @ 28th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  4%|‚ñé         | 29/820 [00:20<09:21,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00059.png-00074.png: 1131 matches @ 29th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  4%|‚ñé         | 30/820 [00:21<09:21,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00046.png-00042.png: 525 matches @ 30th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  4%|‚ñç         | 31/820 [00:22<09:19,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00039.png-00029.png: 2236 matches @ 31th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  4%|‚ñç         | 32/820 [00:22<09:19,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00087.png-00074.png: 328 matches @ 32th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  4%|‚ñç         | 33/820 [00:23<09:18,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00072.png-00111.png: 2078 matches @ 33th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  4%|‚ñç         | 34/820 [00:24<09:17,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00050.png-00039.png: 1865 matches @ 34th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  4%|‚ñç         | 35/820 [00:25<09:17,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00008.png-00010.png: 3318 matches @ 35th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  4%|‚ñç         | 36/820 [00:25<09:16,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00026.png-00010.png: 1865 matches @ 36th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  5%|‚ñç         | 37/820 [00:26<09:16,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00074.png-00076.png: 2149 matches @ 37th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  5%|‚ñç         | 38/820 [00:27<09:15,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00011.png-00013.png: 4230 matches @ 38th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  5%|‚ñç         | 39/820 [00:27<09:14,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00021.png-00029.png: 2168 matches @ 39th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  5%|‚ñç         | 40/820 [00:28<09:13,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00010.png-00006.png: 1584 matches @ 40th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  5%|‚ñå         | 41/820 [00:29<09:13,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00061.png-00074.png: 462 matches @ 41th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  5%|‚ñå         | 42/820 [00:30<09:13,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00069.png-00059.png: 1068 matches @ 42th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  5%|‚ñå         | 43/820 [00:30<09:13,  1.40it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00104.png-00060.png: 91 matches @ 43th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  5%|‚ñå         | 44/820 [00:31<09:12,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00059.png-00061.png: 1112 matches @ 44th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  5%|‚ñå         | 45/820 [00:32<09:11,  1.40it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00032.png-00035.png: 2104 matches @ 45th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  6%|‚ñå         | 46/820 [00:32<09:10,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00026.png-00059.png: 94 matches @ 46th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  6%|‚ñå         | 47/820 [00:33<09:08,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00026.png-00029.png: 1747 matches @ 47th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  6%|‚ñå         | 48/820 [00:34<09:07,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00030.png-00032.png: 908 matches @ 48th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  6%|‚ñå         | 49/820 [00:34<09:06,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00066.png-00059.png: 1141 matches @ 49th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  6%|‚ñå         | 50/820 [00:35<09:05,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00032.png-00039.png: 2451 matches @ 50th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  6%|‚ñå         | 51/820 [00:36<09:06,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00032.png-00066.png: 444 matches @ 51th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  6%|‚ñã         | 52/820 [00:37<09:04,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00035.png-00029.png: 2038 matches @ 52th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  6%|‚ñã         | 53/820 [00:37<09:04,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00030.png-00008.png: 2258 matches @ 53th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  7%|‚ñã         | 54/820 [00:38<09:03,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00032.png-00061.png: 639 matches @ 54th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  7%|‚ñã         | 55/820 [00:39<09:02,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00092.png-00111.png: 1394 matches @ 55th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  7%|‚ñã         | 56/820 [00:39<09:01,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00090.png-00096.png: 139 matches @ 56th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  7%|‚ñã         | 57/820 [00:40<08:59,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00061.png-00076.png: 403 matches @ 57th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  7%|‚ñã         | 58/820 [00:41<08:59,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00026.png-00011.png: 1297 matches @ 58th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  7%|‚ñã         | 59/820 [00:42<08:58,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00068.png-00029.png: 116 matches @ 59th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  7%|‚ñã         | 60/820 [00:42<08:59,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00024.png-00013.png: 2474 matches @ 60th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  7%|‚ñã         | 61/820 [00:43<08:57,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00068.png-00011.png: 521 matches @ 61th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  8%|‚ñä         | 62/820 [00:44<08:57,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00111.png-00074.png: 1210 matches @ 62th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  8%|‚ñä         | 63/820 [00:44<08:56,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00092.png-00059.png: 189 matches @ 63th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  8%|‚ñä         | 64/820 [00:45<08:56,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00032.png-00111.png: 171 matches @ 64th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  8%|‚ñä         | 65/820 [00:46<08:57,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00083.png-00081.png: 1544 matches @ 65th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  8%|‚ñä         | 66/820 [00:47<08:55,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00068.png-00111.png: 934 matches @ 66th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  8%|‚ñä         | 67/820 [00:47<08:54,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00032.png-00010.png: 2132 matches @ 67th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  8%|‚ñä         | 68/820 [00:48<08:53,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00092.png-00074.png: 390 matches @ 68th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  8%|‚ñä         | 69/820 [00:49<08:52,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00024.png-00035.png: 47 matches @ 69th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  9%|‚ñä         | 70/820 [00:49<08:52,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00092.png-00030.png: 173 matches @ 70th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  9%|‚ñä         | 71/820 [00:50<08:51,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00092.png-00026.png: 344 matches @ 71th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  9%|‚ñâ         | 72/820 [00:51<08:50,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00069.png-00032.png: 417 matches @ 72th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  9%|‚ñâ         | 73/820 [00:52<08:49,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00024.png-00011.png: 2019 matches @ 73th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  9%|‚ñâ         | 74/820 [00:52<08:50,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00035.png-00102.png: 4 matches --> skipped\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  9%|‚ñâ         | 75/820 [00:53<08:48,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00026.png-00021.png: 579 matches @ 74th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  9%|‚ñâ         | 76/820 [00:54<08:47,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00024.png-00039.png: 881 matches @ 75th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  9%|‚ñâ         | 77/820 [00:54<08:47,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00035.png-00021.png: 1187 matches @ 76th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 10%|‚ñâ         | 78/820 [00:55<08:46,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00066.png-00111.png: 1272 matches @ 77th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 10%|‚ñâ         | 79/820 [00:56<08:44,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00068.png-00008.png: 954 matches @ 78th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 10%|‚ñâ         | 80/820 [00:56<08:44,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00008.png-00011.png: 3326 matches @ 79th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 10%|‚ñâ         | 81/820 [00:57<08:44,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00069.png-00111.png: 1295 matches @ 80th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 10%|‚ñà         | 82/820 [00:58<08:43,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00010.png-00076.png: 952 matches @ 81th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 10%|‚ñà         | 83/820 [00:59<08:43,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00011.png-00012.png: 4471 matches @ 82th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 10%|‚ñà         | 84/820 [00:59<08:44,  1.40it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00039.png-00011.png: 1400 matches @ 83th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 10%|‚ñà         | 85/820 [01:00<08:43,  1.40it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00021.png-00010.png: 437 matches @ 84th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 10%|‚ñà         | 86/820 [01:01<08:41,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00010.png-00001.png: 1395 matches @ 85th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 11%|‚ñà         | 87/820 [01:01<08:40,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00050.png-00035.png: 659 matches @ 86th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 11%|‚ñà         | 88/820 [01:02<08:39,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00068.png-00039.png: 27 matches @ 87th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 11%|‚ñà         | 89/820 [01:03<08:39,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00029.png-00072.png: 658 matches @ 88th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 11%|‚ñà         | 90/820 [01:04<08:39,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00032.png-00026.png: 941 matches @ 89th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 11%|‚ñà         | 91/820 [01:04<08:38,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00010.png-00066.png: 946 matches @ 90th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 11%|‚ñà         | 92/820 [01:05<08:37,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00021.png-00061.png: 306 matches @ 91th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 11%|‚ñà‚ñè        | 93/820 [01:06<08:35,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00030.png-00074.png: 114 matches @ 92th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 11%|‚ñà‚ñè        | 94/820 [01:06<08:34,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00068.png-00032.png: 239 matches @ 93th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 12%|‚ñà‚ñè        | 95/820 [01:07<08:35,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00032.png-00001.png: 1199 matches @ 94th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 12%|‚ñà‚ñè        | 96/820 [01:08<08:34,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00111.png-00061.png: 112 matches @ 95th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 12%|‚ñà‚ñè        | 97/820 [01:09<08:33,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00032.png-00008.png: 3135 matches @ 96th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 12%|‚ñà‚ñè        | 98/820 [01:09<08:32,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00024.png-00029.png: 791 matches @ 97th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 12%|‚ñà‚ñè        | 99/820 [01:10<08:32,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00030.png-00011.png: 1036 matches @ 98th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 12%|‚ñà‚ñè        | 100/820 [01:11<08:30,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00029.png-00111.png: 580 matches @ 99th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 12%|‚ñà‚ñè        | 101/820 [01:11<08:30,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00087.png-00030.png: 36 matches @ 100th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 12%|‚ñà‚ñè        | 102/820 [01:12<08:29,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00018.png-00011.png: 3083 matches @ 101th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 13%|‚ñà‚ñé        | 103/820 [01:13<08:29,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00030.png-00021.png: 487 matches @ 102th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 13%|‚ñà‚ñé        | 104/820 [01:14<08:27,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00083.png-00021.png: 35 matches @ 103th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 13%|‚ñà‚ñé        | 105/820 [01:14<08:27,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00069.png-00010.png: 964 matches @ 104th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 13%|‚ñà‚ñé        | 106/820 [01:15<08:25,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00087.png-00111.png: 1128 matches @ 105th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 13%|‚ñà‚ñé        | 107/820 [01:16<08:25,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00083.png-00066.png: 955 matches @ 106th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 13%|‚ñà‚ñé        | 108/820 [01:16<08:23,  1.42it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00072.png-00059.png: 676 matches @ 107th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 13%|‚ñà‚ñé        | 109/820 [01:17<08:22,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00008.png-00072.png: 1155 matches @ 108th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 13%|‚ñà‚ñé        | 110/820 [01:18<08:22,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00037.png-00102.png: 36 matches @ 109th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 14%|‚ñà‚ñé        | 111/820 [01:18<08:22,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00010.png-00029.png: 2415 matches @ 110th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 14%|‚ñà‚ñé        | 112/820 [01:19<08:22,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00026.png-00074.png: 99 matches @ 111th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 14%|‚ñà‚ñç        | 113/820 [01:20<08:23,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00032.png-00074.png: 312 matches @ 112th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 14%|‚ñà‚ñç        | 114/820 [01:21<08:22,  1.40it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00001.png-00066.png: 489 matches @ 113th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 14%|‚ñà‚ñç        | 115/820 [01:21<08:22,  1.40it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00030.png-00010.png: 1650 matches @ 114th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 14%|‚ñà‚ñç        | 116/820 [01:22<08:21,  1.40it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00032.png-00059.png: 17 matches @ 115th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 14%|‚ñà‚ñç        | 117/820 [01:23<08:19,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00068.png-00035.png: 343 matches @ 116th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 14%|‚ñà‚ñç        | 118/820 [01:23<08:18,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00012.png-00102.png: 460 matches @ 117th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 15%|‚ñà‚ñç        | 119/820 [01:24<08:17,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00024.png-00012.png: 2330 matches @ 118th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 15%|‚ñà‚ñç        | 120/820 [01:25<08:16,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00001.png-00076.png: 605 matches @ 119th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 15%|‚ñà‚ñç        | 121/820 [01:26<08:17,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00083.png-00061.png: 332 matches @ 120th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 15%|‚ñà‚ñç        | 122/820 [01:26<08:15,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00021.png-00111.png: 161 matches @ 121th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 15%|‚ñà‚ñå        | 123/820 [01:27<08:15,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00008.png-00021.png: 1144 matches @ 122th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 15%|‚ñà‚ñå        | 124/820 [01:28<08:14,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00083.png-00001.png: 339 matches @ 123th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 15%|‚ñà‚ñå        | 125/820 [01:28<08:12,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00012.png-00029.png: 2559 matches @ 124th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 15%|‚ñà‚ñå        | 126/820 [01:29<08:11,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00018.png-00008.png: 2409 matches @ 125th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 15%|‚ñà‚ñå        | 127/820 [01:30<08:10,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00032.png-00076.png: 371 matches @ 126th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 16%|‚ñà‚ñå        | 128/820 [01:31<08:11,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00050.png-00021.png: 1162 matches @ 127th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 16%|‚ñà‚ñå        | 129/820 [01:31<08:10,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00083.png-00096.png: 313 matches @ 128th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 16%|‚ñà‚ñå        | 130/820 [01:32<08:08,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00068.png-00010.png: 363 matches @ 129th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 16%|‚ñà‚ñå        | 131/820 [01:33<08:07,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00059.png-00076.png: 1082 matches @ 130th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 16%|‚ñà‚ñå        | 132/820 [01:33<08:08,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00010.png-00011.png: 2494 matches @ 131th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 16%|‚ñà‚ñå        | 133/820 [01:34<08:08,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00083.png-00069.png: 916 matches @ 132th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 16%|‚ñà‚ñã        | 134/820 [01:35<08:06,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00026.png-00039.png: 328 matches @ 133th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 16%|‚ñà‚ñã        | 135/820 [01:36<08:06,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00068.png-00021.png: 31 matches @ 134th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 17%|‚ñà‚ñã        | 136/820 [01:36<08:06,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00087.png-00059.png: 122 matches @ 135th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 17%|‚ñà‚ñã        | 137/820 [01:37<08:05,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00092.png-00061.png: 165 matches @ 136th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 17%|‚ñà‚ñã        | 138/820 [01:38<08:05,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00021.png-00059.png: 6 matches --> skipped\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 17%|‚ñà‚ñã        | 139/820 [01:38<08:04,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00069.png-00001.png: 508 matches @ 137th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 17%|‚ñà‚ñã        | 140/820 [01:39<08:02,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00018.png-00010.png: 2174 matches @ 138th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 17%|‚ñà‚ñã        | 141/820 [01:40<08:02,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00021.png-00001.png: 532 matches @ 139th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 17%|‚ñà‚ñã        | 142/820 [01:41<08:01,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00010.png-00061.png: 280 matches @ 140th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 17%|‚ñà‚ñã        | 143/820 [01:41<08:01,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00068.png-00024.png: 8 matches --> skipped\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 18%|‚ñà‚ñä        | 144/820 [01:42<08:00,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00032.png-00006.png: 1641 matches @ 141th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 18%|‚ñà‚ñä        | 145/820 [01:43<07:58,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00030.png-00066.png: 404 matches @ 142th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 18%|‚ñà‚ñä        | 146/820 [01:43<07:57,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00024.png-00102.png: 18 matches @ 143th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 18%|‚ñà‚ñä        | 147/820 [01:44<07:57,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00092.png-00072.png: 1754 matches @ 144th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 18%|‚ñà‚ñä        | 148/820 [01:45<07:56,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00018.png-00026.png: 1487 matches @ 145th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 18%|‚ñà‚ñä        | 149/820 [01:45<07:56,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00008.png-00111.png: 896 matches @ 146th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 18%|‚ñà‚ñä        | 150/820 [01:46<07:55,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00111.png-00076.png: 1259 matches @ 147th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 18%|‚ñà‚ñä        | 151/820 [01:47<07:54,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00029.png-00102.png: 374 matches @ 148th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 19%|‚ñà‚ñä        | 152/820 [01:48<07:53,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00021.png-00072.png: 34 matches @ 149th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 19%|‚ñà‚ñä        | 153/820 [01:48<07:52,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00026.png-00066.png: 442 matches @ 150th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 19%|‚ñà‚ñâ        | 154/820 [01:49<07:52,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00069.png-00030.png: 423 matches @ 151th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 19%|‚ñà‚ñâ        | 155/820 [01:50<07:50,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00035.png-00013.png: 260 matches @ 152th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 19%|‚ñà‚ñâ        | 156/820 [01:50<07:50,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00001.png-00061.png: 261 matches @ 153th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 19%|‚ñà‚ñâ        | 157/820 [01:51<07:50,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00083.png-00010.png: 504 matches @ 154th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 19%|‚ñà‚ñâ        | 158/820 [01:52<07:49,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00039.png-00013.png: 594 matches @ 155th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 19%|‚ñà‚ñâ        | 159/820 [01:53<07:48,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00030.png-00039.png: 348 matches @ 156th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 20%|‚ñà‚ñâ        | 160/820 [01:53<07:47,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00010.png-00111.png: 617 matches @ 157th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 20%|‚ñà‚ñâ        | 161/820 [01:54<07:47,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00096.png-00021.png: 71 matches @ 158th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 20%|‚ñà‚ñâ        | 162/820 [01:55<07:47,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00087.png-00026.png: 269 matches @ 159th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 20%|‚ñà‚ñâ        | 163/820 [01:55<07:45,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00092.png-00066.png: 453 matches @ 160th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 20%|‚ñà‚ñà        | 164/820 [01:56<07:45,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00021.png-00011.png: 545 matches @ 161th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 20%|‚ñà‚ñà        | 165/820 [01:57<07:44,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00092.png-00069.png: 461 matches @ 162th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 20%|‚ñà‚ñà        | 166/820 [01:58<07:44,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00083.png-00076.png: 863 matches @ 163th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 20%|‚ñà‚ñà        | 167/820 [01:58<07:42,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00011.png-00072.png: 650 matches @ 164th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 20%|‚ñà‚ñà        | 168/820 [01:59<07:41,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00035.png-00011.png: 1003 matches @ 165th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 21%|‚ñà‚ñà        | 169/820 [02:00<07:41,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00008.png-00076.png: 914 matches @ 166th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 21%|‚ñà‚ñà        | 170/820 [02:00<07:41,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00068.png-00018.png: 150 matches @ 167th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 21%|‚ñà‚ñà        | 171/820 [02:01<07:41,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00008.png-00006.png: 1772 matches @ 168th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 21%|‚ñà‚ñà        | 172/820 [02:02<07:39,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00072.png-00074.png: 2360 matches @ 169th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 21%|‚ñà‚ñà        | 173/820 [02:02<07:38,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00018.png-00013.png: 1522 matches @ 170th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 21%|‚ñà‚ñà        | 174/820 [02:03<07:38,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00069.png-00026.png: 422 matches @ 171th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 21%|‚ñà‚ñà‚ñè       | 175/820 [02:04<07:37,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00026.png-00061.png: 181 matches @ 172th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 21%|‚ñà‚ñà‚ñè       | 176/820 [02:05<07:36,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00092.png-00021.png: 5 matches --> skipped\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 22%|‚ñà‚ñà‚ñè       | 177/820 [02:05<07:35,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00083.png-00006.png: 391 matches @ 173th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 22%|‚ñà‚ñà‚ñè       | 178/820 [02:06<07:36,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00050.png-00013.png: 48 matches @ 174th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 22%|‚ñà‚ñà‚ñè       | 179/820 [02:07<07:35,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00006.png-00076.png: 591 matches @ 175th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 22%|‚ñà‚ñà‚ñè       | 180/820 [02:07<07:34,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00029.png-00059.png: 74 matches @ 176th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 22%|‚ñà‚ñà‚ñè       | 181/820 [02:08<07:34,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00030.png-00061.png: 127 matches @ 177th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 22%|‚ñà‚ñà‚ñè       | 182/820 [02:09<07:32,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00032.png-00072.png: 22 matches @ 178th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 22%|‚ñà‚ñà‚ñè       | 183/820 [02:10<07:31,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00092.png-00083.png: 17 matches @ 179th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 22%|‚ñà‚ñà‚ñè       | 184/820 [02:10<07:30,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00087.png-00061.png: 400 matches @ 180th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 23%|‚ñà‚ñà‚ñé       | 185/820 [02:11<07:29,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00021.png-00066.png: 39 matches @ 181th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 23%|‚ñà‚ñà‚ñé       | 186/820 [02:12<07:29,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00013.png-00029.png: 615 matches @ 182th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 23%|‚ñà‚ñà‚ñé       | 187/820 [02:12<07:28,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00083.png-00074.png: 821 matches @ 183th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 23%|‚ñà‚ñà‚ñé       | 188/820 [02:13<07:27,  1.41it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00013.png-00102.png: 179 matches @ 184th pair(aliked+lightglue)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 23%|‚ñà‚ñà‚ñé       | 189/820 [02:14<07:27,  1.41it/s]",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Result"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.011953,
          "end_time": "2024-05-01T06:58:41.753769",
          "exception": false,
          "start_time": "2024-05-01T06:58:41.741816",
          "status": "completed"
        },
        "tags": [],
        "id": "CspdZCbAA0ar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat submission.csv"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.981493,
          "end_time": "2024-05-01T06:58:42.747218",
          "exception": false,
          "start_time": "2024-05-01T06:58:41.765725",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "kEIxHhJjA0ar"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}