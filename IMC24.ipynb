{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 71885,
          "databundleVersionId": 8143495,
          "sourceType": "competition"
        },
        {
          "sourceId": 7884485,
          "sourceType": "datasetVersion",
          "datasetId": 4628051
        },
        {
          "sourceId": 172469456,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 4534,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 3326
        },
        {
          "sourceId": 17191,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 14317
        },
        {
          "sourceId": 17555,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 14611
        }
      ],
      "dockerImageVersionId": 30684,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "IMC24",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ktichola/Image-matching/blob/main/IMC24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'image-matching-challenge-2024:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F71885%2F8143495%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240514%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240514T111730Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D74b671bffd14fbd08641eaa7cca883400002117113aae93674b984a8d9c5cc3d19ffc98195d4e84b5aa3a24bba482c98cd660cbf2059495c7052647a4b63cafdde03322eeac4d0fc6dd5a3717d251b93f69f02d127c1e048860aafbd58b275cfdc90741d65867cd15a288458c27e556a8fd40df8f205796a4f00f65ed753e1751c8ad901a28e6767fd1091266ce095dddbb187782753f29f57548600909c255c3a0eca7d53fa7257c5d41dd052217fcf159d95c81235b2e55def075af72e902e996289397c28fae0c4f8ffc626affbcea4e8f48809ab46ce57f21efe8e06f9fe37df0542f822b9370de8e21fd79586d04c1731a9b6e8d01614a00402633e2ac7,imc2024-packages-lightglue-rerun-kornia:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4628051%2F7884485%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240514%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240514T111730Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Db038ff16185b6091ffae2562789fec3441aa34752ddd13bb0005473953000c510ef052880218900b455580edf36e71239ee1ac5b6006d6c4ddef928b0630cfdc24d63855ada672c830688d0794dc18671454224a5e598fcb4969bba24917cd197b8b0a55c423e5f533be3f89ee6b3cefd3e8886e0edb2a903e1e16a23d847320e026abf6954c4b659e488f0d9faad73a429ee9cc2e41e4f444439c9fb1d4245ba1709609134b68e371b80324db1683327b2bc31b11217d61780b8712712d9f7b1285421d8ea828f12bfd7d7337793a4389ef9d0cd1bbef2d864267448a627c3886186589c5dac946c7d4bbf376cbeb294f277258ca6bfa1de23fe15067508407,dinov2/pytorch/base/1:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-models-data%2F3326%2F4534%2Fbundle%2Farchive.tar.gz%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240514%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240514T111730Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Dafc13f5ca2fc6a5f8bc8e80eb5499d940b1dcc7492c6b18cafec3688d2efee6abd83b86e23afb90ab1f774cc28da9825ec4a49f50367ed761c561e00012b11d0fa70b585b3aed41e0cd9015b8e73dd9ef2a0f4432b24ea70fe10ed980625ccbd8774808d6cc8ea8640fec47172289230539744f0d4643c0b8780379ea8a9c3eb09cd15e47bc2b923ac1aed05ed3ffe24bfd8f57f18f9d9ef9ed3536c3b26a540d93504ff072d003df133db575a6cf8e45302adc154dbffba327a7a92b6e7e75b88f8e5177c8a4618d09e60eeeb1836b7c6bcbae3489c2520a3ee8ff5f8b2a85fb08d58d1633df5fcebc59166c2634c99638ccf0f9fd59d2534815ee23c131f66,lightglue/pytorch/aliked/1:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-models-data%2F14317%2F17191%2Fbundle%2Farchive.tar.gz%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240514%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240514T111730Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D5d26c8225634a41e74918a2f35130ddcf5dea38e9ce3ecb0a4bbe3ee89a07f3216b9f90dc90de329a1ce0196efdf9490be7b4e2d9be85176567b2352ce0afb63e2e252849c0629186a1f3ba9d4035d03e8fd2cce13bf2a2fd840e3dd510cd4f4c4403b708f42689c75f976697036f5f9c67ee0248171a08ea038dd8c80db1dab7be1d42b6458608b3c6fa4108e5829dd233549043fafa107b37f0b2131023cd2186bb5dba011bfa6fd0f97b49228d896df0e2387f9c9e5f5d596344aa4f6c917f9f6c09a9e61947fc49b58bb664c92c40ea12956c3f0eb11cebd63251ef24110a61e44fe057398b9bc1d7cb4bdcb11ee4be4ca6fcc7476397a753d99c373a5c1,aliked/pytorch/aliked-n16/1:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-models-data%2F14611%2F17555%2Fbundle%2Farchive.tar.gz%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240514%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240514T111730Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D3702ef1610d3da2f1e0800a5c1650021ff41f8af2fa0039b75e66d2e33702c1d4ad53629b2f5559441b1461df0f31d1c4cdfd1ccde5f315cdb650226c07d1a46a545eb5e2807343519e81f915440e2155bd1398c3d588c258dc4d679dc2c6e1b3c038fdaf17b1855a3d065274ab74c3b48924fc1a7e73f09381898183ce0c2aef6f1dc77daee968e1390269c28e9ff3886613df6a40a1a15173dae3b40ce22f7d808989ebbbe2f6faf6959582ef58103e8a8ade0fa8072457ce5dc5cc670b4cf7206743fe30528c232d62f3ab6b8d7a3e1da278ccefc2a0118f1dbff1af59aa2c304d1bf616ece7bf0674b86861499c49049d322a68a922b1c81dcb66578d639'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "OB9EIQEc0mlt"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SETUP"
      ],
      "metadata": {
        "id": "ubPO6ewG0mlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "!pip install -r /kaggle/input/check-image-orientation/requirements.txt\n",
        "!pip install --no-index /kaggle/input/imc2024-packages-lightglue-rerun-kornia/* --no-deps\n",
        "!mkdir -p /root/.cache/torch/hub/checkpoints\n",
        "!cp /kaggle/input/aliked/pytorch/aliked-n16/1/* /root/.cache/torch/hub/checkpoints/\n",
        "!cp /kaggle/input/lightglue/pytorch/aliked/1/* /root/.cache/torch/hub/checkpoints/\n",
        "!cp /kaggle/input/lightglue/pytorch/aliked/1/aliked_lightglue.pth /root/.cache/torch/hub/checkpoints/aliked_lightglue_v0-1_arxiv-pth\n",
        "!cp /kaggle/input/check-image-orientation/2020-11-16_resnext50_32x4d.zip /root/.cache/torch/hub/checkpoints/\n",
        "\n",
        "clear_output(wait=False)"
      ],
      "metadata": {
        "_uuid": "085d1ffd-0238-4af9-aee2-16500ee2a223",
        "_cell_guid": "0cdd81c0-04bc-42f7-b697-671da238b617",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-05-14T11:15:34.043946Z",
          "iopub.execute_input": "2024-05-14T11:15:34.044678Z",
          "iopub.status.idle": "2024-05-14T11:16:07.024562Z",
          "shell.execute_reply.started": "2024-05-14T11:15:34.044626Z",
          "shell.execute_reply": "2024-05-14T11:16:07.022825Z"
        },
        "trusted": true,
        "id": "ZAil8igX0mlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from copy import deepcopy\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import pandas.api.types\n",
        "from itertools import combinations\n",
        "import sys, torch, h5py, pycolmap, datetime\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "import kornia as K\n",
        "import kornia.feature as KF\n",
        "from lightglue.utils import load_image\n",
        "from lightglue import LightGlue, ALIKED, match_pair\n",
        "from transformers import AutoImageProcessor, AutoModel\n",
        "from check_orientation.pre_trained_models import create_model\n",
        "sys.path.append(\"/kaggle/input/colmap-db-import\")\n",
        "from database import *\n",
        "from h5_to_db import *\n",
        "\n",
        "IMC_PATH = '/kaggle/input/image-matching-challenge-2024'\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "clear_output(wait=False)"
      ],
      "metadata": {
        "_uuid": "2ca8bfe2-ceb8-4c67-8bf4-69dee8ad81b2",
        "_cell_guid": "9845a075-97c8-48f4-b50f-ad12fcbfa74f",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-05-14T11:16:07.02782Z",
          "iopub.execute_input": "2024-05-14T11:16:07.02846Z",
          "iopub.status.idle": "2024-05-14T11:16:35.366594Z",
          "shell.execute_reply.started": "2024-05-14T11:16:07.028422Z",
          "shell.execute_reply": "2024-05-14T11:16:35.363969Z"
        },
        "trusted": true,
        "id": "EJn5rWqx0mlv",
        "outputId": "ee0d40d2-d898-4311-9a0c-be23983968f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "2024-05-14 11:16:20.724728: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-14 11:16:20.724865: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-14 11:16:20.872882: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name swsl_resnext50_32x4d to current resnext50_32x4d.fb_swsl_ig1b_ft_in1k.\n  model = create_fn(\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcheck_orientation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpre_trained_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_model\n\u001b[1;32m     19\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/colmap-db-import\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatabase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mh5_to_db\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     23\u001b[0m IMC_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/image-matching-challenge-2024\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'database'"
          ],
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'database'",
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CHECK IMAGE ORIENTATION"
      ],
      "metadata": {
        "id": "ss9BHGTq0mlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rotate_image(image,rotation):\n",
        "    for i in range(4):\n",
        "        with torch.no_grad():\n",
        "            pred = rotation(image[None,...]).argmax()\n",
        "        if pred == 0: break\n",
        "        image = image.rot90(dims=[1,2])\n",
        "    return image"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-14T11:16:35.367909Z",
          "iopub.status.idle": "2024-05-14T11:16:35.368405Z",
          "shell.execute_reply.started": "2024-05-14T11:16:35.3682Z",
          "shell.execute_reply": "2024-05-14T11:16:35.368217Z"
        },
        "trusted": true,
        "id": "Uu-CJjTK0mlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OVERLAP DETECTION"
      ],
      "metadata": {
        "id": "tT2NXeD50mlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def overlap_detection(extractor, matcher, image0, image1, min_matches):\n",
        "    feats0, feats1, matches01 = match_pair(extractor, matcher, image0, image1)\n",
        "    if len(matches01['matches']) < min_matches:\n",
        "        return feats0, feats1, matches01\n",
        "    kpts0, kpts1, matches = feats0[\"keypoints\"], feats1[\"keypoints\"], matches01[\"matches\"]\n",
        "    m_kpts0, m_kpts1 = kpts0[matches[..., 0]], kpts1[matches[..., 1]]\n",
        "    left0, top0 = m_kpts0.numpy().min(axis=0).astype(int)\n",
        "    width0, height0 = m_kpts0.numpy().max(axis=0).astype(int)\n",
        "    height0 -= top0\n",
        "    width0 -= left0\n",
        "    left1, top1 = m_kpts1.numpy().min(axis=0).astype(int)\n",
        "    width1, height1 = m_kpts1.numpy().max(axis=0).astype(int)\n",
        "    height1 -= top1\n",
        "    width1 -= left1\n",
        "    crop_box0 = (top0, left0, height0, width0)\n",
        "    crop_box1 = (top1, left1, height1, width1)\n",
        "    cropped_img_tensor0 = TF.crop(image0, *crop_box0)\n",
        "    cropped_img_tensor1 = TF.crop(image1, *crop_box1)\n",
        "    feats0_c, feats1_c, matches01_c = match_pair(extractor, matcher, cropped_img_tensor0, cropped_img_tensor1)\n",
        "    feats0_c['keypoints'][...,0] += left0\n",
        "    feats0_c['keypoints'][...,1] += top0\n",
        "    feats1_c['keypoints'][...,0] += left1\n",
        "    feats1_c['keypoints'][...,1] += top1\n",
        "    return feats0_c, feats1_c, matches01_c"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-14T11:16:35.369611Z",
          "iopub.status.idle": "2024-05-14T11:16:35.370024Z",
          "shell.execute_reply.started": "2024-05-14T11:16:35.369834Z",
          "shell.execute_reply": "2024-05-14T11:16:35.36985Z"
        },
        "trusted": true,
        "id": "UB6vW_490mlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SUBMISSION"
      ],
      "metadata": {
        "id": "bkodRk-90mlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reset_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "def parse_sample_submission(data_path):\n",
        "    data_dict = {}\n",
        "    with open(data_path, \"r\") as f:\n",
        "        for i, l in enumerate(f):\n",
        "            if i == 0:\n",
        "                print(\"header:\", l)\n",
        "\n",
        "            if l and i > 0:\n",
        "                image_path, dataset, scene, _, _ = l.strip().split(',')\n",
        "                if dataset not in data_dict:\n",
        "                    data_dict[dataset] = {}\n",
        "                if scene not in data_dict[dataset]:\n",
        "                    data_dict[dataset][scene] = []\n",
        "                data_dict[dataset][scene].append(Path(IMC_PATH +'/'+ image_path))\n",
        "\n",
        "    for dataset in data_dict:\n",
        "        for scene in data_dict[dataset]:\n",
        "            print(f\"{dataset} / {scene} -> {len(data_dict[dataset][scene])} images\")\n",
        "\n",
        "    return data_dict\n",
        "\n",
        "def arr_to_str(a):\n",
        "    return \";\".join([str(x) for x in a.reshape(-1)])"
      ],
      "metadata": {
        "_uuid": "1a935a33-c8c9-4e79-9b24-7aadbe88e740",
        "_cell_guid": "19a390a5-0c4d-49a6-ad3e-e803fc5cce90",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-05-14T11:16:35.371923Z",
          "iopub.status.idle": "2024-05-14T11:16:35.373737Z",
          "shell.execute_reply.started": "2024-05-14T11:16:35.373366Z",
          "shell.execute_reply": "2024-05-14T11:16:35.373399Z"
        },
        "trusted": true,
        "id": "TocameRI0mly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_submission(results,data_dict,base_path):\n",
        "    with open(\"submission.csv\", \"w\") as f:\n",
        "        f.write(\"image_path,dataset,scene,rotation_matrix,translation_vector\\n\")\n",
        "\n",
        "        for dataset in data_dict:\n",
        "            if dataset in results:\n",
        "                res = results[dataset]\n",
        "            else:\n",
        "                res = {}\n",
        "\n",
        "            for scene in data_dict[dataset]:\n",
        "                if scene in res:\n",
        "                    scene_res = res[scene]\n",
        "                else:\n",
        "                    scene_res = {\"R\":{}, \"t\":{}}\n",
        "\n",
        "                for image in data_dict[dataset][scene]:\n",
        "                    if image in scene_res:\n",
        "                        R = scene_res[image][\"R\"].reshape(-1)\n",
        "                        T = scene_res[image][\"t\"].reshape(-1)\n",
        "                    else:\n",
        "                        R = np.eye(3).reshape(-1)\n",
        "                        T = np.zeros((3))\n",
        "                    image_path = str(image.relative_to(base_path))\n",
        "                    f.write(f\"{image_path},{dataset},{scene},{arr_to_str(R)},{arr_to_str(T)}\\n\")"
      ],
      "metadata": {
        "_uuid": "dad1dfb0-4aa9-4163-b9ea-d2653d0888ea",
        "_cell_guid": "27c7bb8e-5a45-45f1-9ac4-faf8f78216cf",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-05-14T11:16:35.37502Z",
          "iopub.status.idle": "2024-05-14T11:16:35.375599Z",
          "shell.execute_reply.started": "2024-05-14T11:16:35.375322Z",
          "shell.execute_reply": "2024-05-14T11:16:35.375344Z"
        },
        "trusted": true,
        "id": "tQOjJw_n0ml0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(data_path,get_pairs,keypoints_matches,ransac_and_sparse_reconstruction,submit=True):\n",
        "    results = {}\n",
        "\n",
        "    data_dict = parse_sample_submission(data_path)\n",
        "    datasets = list(data_dict.keys())\n",
        "\n",
        "    for dataset in datasets:\n",
        "        if dataset not in results:\n",
        "            results[dataset] = {}\n",
        "\n",
        "        for scene in data_dict[dataset]:\n",
        "            images_dir = data_dict[dataset][scene][0].parent\n",
        "            results[dataset][scene] = {}\n",
        "            image_paths = data_dict[dataset][scene]\n",
        "\n",
        "            index_pairs = get_pairs(image_paths)\n",
        "            keypoints_matches(image_paths,index_pairs)\n",
        "            maps = ransac_and_sparse_reconstruction(image_paths[0].parent)\n",
        "            clear_output(wait=False)\n",
        "\n",
        "            path = 'test' if submit else 'train'\n",
        "            images_registered  = 0\n",
        "            best_idx = 0\n",
        "            for idx, rec in maps.items():\n",
        "                if len(rec.images) > images_registered:\n",
        "                    images_registered = len(rec.images)\n",
        "                    best_idx = idx\n",
        "\n",
        "            for k, im in maps[best_idx].images.items():\n",
        "                key = Path(IMC_PATH) / path / scene / \"images\" / im.name\n",
        "                results[dataset][scene][key] = {}\n",
        "                results[dataset][scene][key][\"R\"] = deepcopy(im.cam_from_world.rotation.matrix())\n",
        "                results[dataset][scene][key][\"t\"] = deepcopy(np.array(im.cam_from_world.translation))\n",
        "\n",
        "            create_submission(results, data_dict, Path(IMC_PATH))"
      ],
      "metadata": {
        "_uuid": "68f0a367-8655-444e-a38e-567c6aa3911f",
        "_cell_guid": "23d92c5b-13b2-4420-87a6-6037747fd98c",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-05-14T11:16:35.377835Z",
          "iopub.status.idle": "2024-05-14T11:16:35.378462Z",
          "shell.execute_reply.started": "2024-05-14T11:16:35.378156Z",
          "shell.execute_reply": "2024-05-14T11:16:35.37818Z"
        },
        "trusted": true,
        "id": "lm0AKuKs0ml1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# mAA METRIC"
      ],
      "metadata": {
        "id": "Yyor0_T40ml1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_EPS = np.finfo(float).eps * 4.0\n",
        "\n",
        "# mAA evaluation thresholds per scene, different accoring to the scene\n",
        "translation_thresholds_meters_dict = {\n",
        " 'multi-temporal-temple-baalshamin':  np.array([0.025,  0.05,  0.1,  0.2,  0.5,  1.0]),\n",
        " 'pond':                              np.array([0.025,  0.05,  0.1,  0.2,  0.5,  1.0]),\n",
        " 'transp_obj_glass_cylinder':         np.array([0.0025, 0.005, 0.01, 0.02, 0.05, 0.1]),\n",
        " 'transp_obj_glass_cup':              np.array([0.0025, 0.005, 0.01, 0.02, 0.05, 0.1]),\n",
        " 'church':                            np.array([0.025,  0.05,  0.1,  0.2,  0.5,  1.0]),\n",
        " 'lizard':                            np.array([0.025,  0.05,  0.1,  0.2,  0.5,  1.0]),\n",
        " 'dioscuri':                          np.array([0.025,  0.05,  0.1,  0.2,  0.5,  1.0]),\n",
        "}\n",
        "\n",
        "\n",
        "def vector_norm(data, axis=None, out=None):\n",
        "    '''Return length, i.e. Euclidean norm, of ndarray along axis.'''\n",
        "    data = np.array(data, dtype=np.float64, copy=True)\n",
        "    if out is None:\n",
        "        if data.ndim == 1:\n",
        "            return math.sqrt(np.dot(data, data))\n",
        "        data *= data\n",
        "        out = np.atleast_1d(np.sum(data, axis=axis))\n",
        "        np.sqrt(out, out)\n",
        "        return out\n",
        "    data *= data\n",
        "    np.sum(data, axis=axis, out=out)\n",
        "    np.sqrt(out, out)\n",
        "    return None\n",
        "\n",
        "\n",
        "def quaternion_matrix(quaternion):\n",
        "    '''Return homogeneous rotation matrix from quaternion.'''\n",
        "    q = np.array(quaternion, dtype=np.float64, copy=True)\n",
        "    n = np.dot(q, q)\n",
        "    if n < _EPS:\n",
        "        # print(\"special case\")\n",
        "        return np.identity(4)\n",
        "    q *= math.sqrt(2.0 / n)\n",
        "    q = np.outer(q, q)\n",
        "    return np.array(\n",
        "        [\n",
        "            [\n",
        "                1.0 - q[2, 2] - q[3, 3],\n",
        "                q[1, 2] - q[3, 0],\n",
        "                q[1, 3] + q[2, 0],\n",
        "                0.0,\n",
        "            ],\n",
        "            [\n",
        "                q[1, 2] + q[3, 0],\n",
        "                1.0 - q[1, 1] - q[3, 3],\n",
        "                q[2, 3] - q[1, 0],\n",
        "                0.0,\n",
        "            ],\n",
        "            [\n",
        "                q[1, 3] - q[2, 0],\n",
        "                q[2, 3] + q[1, 0],\n",
        "                1.0 - q[1, 1] - q[2, 2],\n",
        "                0.0,\n",
        "            ],\n",
        "            [0.0, 0.0, 0.0, 1.0],\n",
        "        ]\n",
        "    )\n",
        "\n",
        "\n",
        "# based on the 3D registration from https://github.com/cgohlke/transformations\n",
        "def affine_matrix_from_points(v0, v1, shear=False, scale=True, usesvd=True):\n",
        "\n",
        "    v0 = np.array(v0, dtype=np.float64, copy=True)\n",
        "    v1 = np.array(v1, dtype=np.float64, copy=True)\n",
        "\n",
        "    ndims = v0.shape[0]\n",
        "    if ndims < 2 or v0.shape[1] < ndims or v0.shape != v1.shape:\n",
        "        raise ValueError(\"input arrays are of wrong shape or type\")\n",
        "\n",
        "    # move centroids to origin\n",
        "    t0 = -np.mean(v0, axis=1)\n",
        "    M0 = np.identity(ndims + 1)\n",
        "    M0[:ndims, ndims] = t0\n",
        "    v0 += t0.reshape(ndims, 1)\n",
        "    t1 = -np.mean(v1, axis=1)\n",
        "    M1 = np.identity(ndims + 1)\n",
        "    M1[:ndims, ndims] = t1\n",
        "    v1 += t1.reshape(ndims, 1)\n",
        "\n",
        "    if shear:\n",
        "        # Affine transformation\n",
        "        A = np.concatenate((v0, v1), axis=0)\n",
        "        u, s, vh = np.linalg.svd(A.T)\n",
        "        vh = vh[:ndims].T\n",
        "        B = vh[:ndims]\n",
        "        C = vh[ndims: 2 * ndims]\n",
        "        t = np.dot(C, np.linalg.pinv(B))\n",
        "        t = np.concatenate((t, np.zeros((ndims, 1))), axis=1)\n",
        "        M = np.vstack((t, ((0.0,) * ndims) + (1.0,)))\n",
        "    elif usesvd or ndims != 3:\n",
        "        # Rigid transformation via SVD of covariance matrix\n",
        "        u, s, vh = np.linalg.svd(np.dot(v1, v0.T))\n",
        "        # rotation matrix from SVD orthonormal bases\n",
        "        R = np.dot(u, vh)\n",
        "        if np.linalg.det(R) < 0.0:\n",
        "            # R does not constitute right handed system\n",
        "            R -= np.outer(u[:, ndims - 1], vh[ndims - 1, :] * 2.0)\n",
        "            s[-1] *= -1.0\n",
        "        # homogeneous transformation matrix\n",
        "        M = np.identity(ndims + 1)\n",
        "        M[:ndims, :ndims] = R\n",
        "    else:\n",
        "        # Rigid transformation matrix via quaternion\n",
        "        # compute symmetric matrix N\n",
        "        xx, yy, zz = np.sum(v0 * v1, axis=1)\n",
        "        xy, yz, zx = np.sum(v0 * np.roll(v1, -1, axis=0), axis=1)\n",
        "        xz, yx, zy = np.sum(v0 * np.roll(v1, -2, axis=0), axis=1)\n",
        "        N = [\n",
        "            [xx + yy + zz, 0.0, 0.0, 0.0],\n",
        "            [yz - zy, xx - yy - zz, 0.0, 0.0],\n",
        "            [zx - xz, xy + yx, yy - xx - zz, 0.0],\n",
        "            [xy - yx, zx + xz, yz + zy, zz - xx - yy],\n",
        "        ]\n",
        "        # quaternion: eigenvector corresponding to most positive eigenvalue\n",
        "        w, V = np.linalg.eigh(N)\n",
        "        q = V[:, np.argmax(w)]\n",
        "        # print (vector_norm(q), np.linalg.norm(q))\n",
        "        q /= vector_norm(q)  # unit quaternion\n",
        "        # homogeneous transformation matrix\n",
        "        M = quaternion_matrix(q)\n",
        "\n",
        "    if scale and not shear:\n",
        "        # Affine transformation; scale is ratio of RMS deviations from centroid\n",
        "        v0 *= v0\n",
        "        v1 *= v1\n",
        "        M[:ndims, :ndims] *= math.sqrt(np.sum(v1) / np.sum(v0))\n",
        "\n",
        "    # move centroids back\n",
        "    M = np.dot(np.linalg.inv(M1), np.dot(M, M0))\n",
        "    M /= M[ndims, ndims]\n",
        "\n",
        "    # print(\"transformation matrix Python Script: \", M)\n",
        "\n",
        "    return M\n",
        "\n",
        "\n",
        "# This is the IMC 3D error metric code\n",
        "def register_by_Horn(ev_coord, gt_coord, ransac_threshold, inl_cf, strict_cf):\n",
        "\n",
        "    # remove invalid cameras, the index is returned\n",
        "    idx_cams = np.all(np.isfinite(ev_coord), axis=0)\n",
        "    ev_coord = ev_coord[:, idx_cams]\n",
        "    gt_coord = gt_coord[:, idx_cams]\n",
        "\n",
        "    # initialization\n",
        "    n = ev_coord.shape[1]\n",
        "    r = ransac_threshold.shape[0]\n",
        "    ransac_threshold = np.expand_dims(ransac_threshold, axis=0)\n",
        "    ransac_threshold2 = ransac_threshold**2\n",
        "    ev_coord_1 = np.vstack((ev_coord, np.ones(n)))\n",
        "\n",
        "    max_no_inl = np.zeros((1, r))\n",
        "    best_inl_err = np.full(r, np.Inf)\n",
        "    best_transf_matrix = np.zeros((r, 4, 4))\n",
        "    best_err = np.full((n, r), np.Inf)\n",
        "    strict_inl = np.full((n, r), False)\n",
        "    triplets_used = np.zeros((3, r))\n",
        "\n",
        "    # run on camera triplets\n",
        "    for ii in range(n-2):\n",
        "        for jj in range(ii+1, n-1):\n",
        "            for kk in range(jj+1, n):\n",
        "                i = [ii, jj, kk]\n",
        "                triplets_used_now = np.full((n), False)\n",
        "                triplets_used_now[i] = True\n",
        "                # if both ii, jj, kk are strict inliers for the best current model just skip\n",
        "                if np.all(strict_inl[i]):\n",
        "                    continue\n",
        "                # get transformation T by Horn on the triplet camera center correspondences\n",
        "                transf_matrix = affine_matrix_from_points(ev_coord[:, i], gt_coord[:, i], usesvd=False)\n",
        "                # apply transformation T to test camera centres\n",
        "                rotranslated = np.matmul(transf_matrix[:3], ev_coord_1)\n",
        "                # compute error and inliers\n",
        "                err = np.sum((rotranslated - gt_coord)**2, axis=0)\n",
        "                inl = np.expand_dims(err, axis=1) < ransac_threshold2\n",
        "                no_inl = np.sum(inl, axis=0)\n",
        "                # if the number of inliers is close to that of the best model so far, go for refinement\n",
        "                to_ref = np.squeeze(((no_inl > 2) & (no_inl > max_no_inl * inl_cf)), axis=0)\n",
        "                for q in np.argwhere(to_ref):\n",
        "                    qq = q[0]\n",
        "                    if np.any(np.all((np.expand_dims(inl[:, qq], axis=1) == inl[:, :qq]), axis=0)):\n",
        "                        # already done for this set of inliers\n",
        "                        continue\n",
        "                    # get transformation T by Horn on the inlier camera center correspondences\n",
        "                    transf_matrix = affine_matrix_from_points(ev_coord[:, inl[:, qq]], gt_coord[:, inl[:, qq]])\n",
        "                    # apply transformation T to test camera centres\n",
        "                    rotranslated = np.matmul(transf_matrix[:3], ev_coord_1)\n",
        "                    # compute error and inliers\n",
        "                    err_ref = np.sum((rotranslated - gt_coord)**2, axis=0)\n",
        "                    err_ref_sum = np.sum(err_ref, axis=0)\n",
        "                    err_ref = np.expand_dims(err_ref, axis=1)\n",
        "                    inl_ref = err_ref < ransac_threshold2\n",
        "                    no_inl_ref = np.sum(inl_ref, axis=0)\n",
        "                    # update the model if better for each threshold\n",
        "                    to_update = np.squeeze((no_inl_ref > max_no_inl) | ((no_inl_ref == max_no_inl) & (err_ref_sum < best_inl_err)), axis=0)\n",
        "                    if np.any(to_update):\n",
        "                        triplets_used[0, to_update] = ii\n",
        "                        triplets_used[1, to_update] = jj\n",
        "                        triplets_used[2, to_update] = kk\n",
        "                        max_no_inl[:, to_update] = no_inl_ref[to_update]\n",
        "                        best_err[:, to_update] = np.sqrt(err_ref)\n",
        "                        best_inl_err[to_update] = err_ref_sum\n",
        "                        strict_inl[:, to_update] = (best_err[:, to_update] < strict_cf * ransac_threshold[:, to_update])\n",
        "                        best_transf_matrix[to_update] = transf_matrix\n",
        "\n",
        "#     for i in range(r):\n",
        "#        print(f'Registered cameras {int(max_no_inl[0, i])}/{n} for threshold {ransac_threshold[0, i]}')\n",
        "\n",
        "    best_model = {\n",
        "        \"valid_cams\": idx_cams,\n",
        "        \"no_inl\": max_no_inl,\n",
        "        \"err\": best_err,\n",
        "        \"triplets_used\": triplets_used,\n",
        "        \"transf_matrix\": best_transf_matrix}\n",
        "    return best_model\n",
        "\n",
        "\n",
        "# mAA computation\n",
        "def mAA_on_cameras(err, thresholds, n, skip_top_thresholds, to_dec=3):\n",
        "\n",
        "    aux = err[:, skip_top_thresholds:] < np.expand_dims(np.asarray(thresholds[skip_top_thresholds:]), axis=0)\n",
        "    return np.sum(np.maximum(np.sum(aux, axis=0) - to_dec, 0)) / (len(thresholds[skip_top_thresholds:]) * (n - to_dec))\n",
        "\n",
        "\n",
        "# import data - no error handling in case float(x) fails\n",
        "def get_camera_centers_from_df(df):\n",
        "    out = {}\n",
        "    for row in df.iterrows():\n",
        "        row = row[1]\n",
        "        fname = row['image_path']\n",
        "        R = np.array([float(x) for x in (row['rotation_matrix'].split(';'))]).reshape(3,3)\n",
        "        t = np.array([float(x) for x in (row['translation_vector'].split(';'))]).reshape(3)\n",
        "        center = -R.T @ t\n",
        "        out[fname] = center\n",
        "    return out\n",
        "\n",
        "\n",
        "def evaluate_rec(gt_df, user_df, inl_cf = 0.8, strict_cf=0.5, skip_top_thresholds=2, to_dec=3,\n",
        "                 thresholds=[0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2]):\n",
        "    # get camera centers\n",
        "    ucameras = get_camera_centers_from_df(user_df)\n",
        "    gcameras = get_camera_centers_from_df(gt_df)\n",
        "\n",
        "    # the denominator for mAA ratio\n",
        "    m = gt_df.shape[0]\n",
        "\n",
        "    # get the image list to use\n",
        "    good_cams = []\n",
        "    for image_path in gcameras.keys():\n",
        "        if image_path in ucameras.keys():\n",
        "            good_cams.append(image_path)\n",
        "\n",
        "    # put corresponding camera centers into matrices\n",
        "    n = len(good_cams)\n",
        "    u_cameras = np.zeros((3, n))\n",
        "    g_cameras = np.zeros((3, n))\n",
        "\n",
        "    ii = 0\n",
        "    for i in good_cams:\n",
        "        u_cameras[:, ii] = ucameras[i]\n",
        "        g_cameras[:, ii] = gcameras[i]\n",
        "        ii += 1\n",
        "\n",
        "    # Horn camera centers registration, a different best model for each camera threshold\n",
        "    model = register_by_Horn(u_cameras, g_cameras, np.asarray(thresholds), inl_cf, strict_cf)\n",
        "\n",
        "    # transformation matrix\n",
        "#     print(\"\\nTransformation matrix for maximum threshold\")\n",
        "    T = np.squeeze(model['transf_matrix'][-1])\n",
        "#     print(T)\n",
        "\n",
        "    # mAA\n",
        "    mAA = mAA_on_cameras(model[\"err\"], thresholds, m, skip_top_thresholds, to_dec)\n",
        "    # print(f'mAA = {mAA * 100 : .2f}% considering {m} input cameras - {to_dec}')\n",
        "    return mAA\n",
        "\n",
        "\n",
        "def score(solution: pd.DataFrame, submission: pd.DataFrame) -> float:\n",
        "\n",
        "    scenes = list(set(solution['dataset'].tolist()))\n",
        "    results_per_dataset = []\n",
        "    for dataset in scenes:\n",
        "        print(f\"\\n*** {dataset} ***\")\n",
        "#         start = time.time()\n",
        "        gt_ds = solution[solution['dataset'] == dataset]\n",
        "        user_ds = submission[submission['dataset'] == dataset]\n",
        "        gt_ds = gt_ds.sort_values(by=['image_path'], ascending = True)\n",
        "        user_ds = user_ds.sort_values(by=['image_path'], ascending = True)\n",
        "        result = evaluate_rec(gt_ds, user_ds, inl_cf=0, strict_cf=-1, skip_top_thresholds=0, to_dec=3,\n",
        "                 thresholds=translation_thresholds_meters_dict[dataset])\n",
        "#         end = time.time()\n",
        "        print(f\"\\nmAA: {round(result,4)}\")\n",
        "#         print(\"Running time: %s\" % (end - start))\n",
        "        results_per_dataset.append(result)\n",
        "    return float(np.array(results_per_dataset).mean())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-14T11:17:14.026969Z",
          "iopub.execute_input": "2024-05-14T11:17:14.027376Z",
          "iopub.status.idle": "2024-05-14T11:17:14.10041Z",
          "shell.execute_reply.started": "2024-05-14T11:17:14.027348Z",
          "shell.execute_reply": "2024-05-14T11:17:14.098224Z"
        },
        "trusted": true,
        "id": "3iP9zwPG0ml2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}