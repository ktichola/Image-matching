{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 71885,
          "databundleVersionId": 8143495,
          "sourceType": "competition"
        },
        {
          "sourceId": 7884485,
          "sourceType": "datasetVersion",
          "datasetId": 4628051
        },
        {
          "sourceId": 7884725,
          "sourceType": "datasetVersion",
          "datasetId": 4628331
        },
        {
          "sourceId": 4534,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 3326
        },
        {
          "sourceId": 17191,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 14317
        },
        {
          "sourceId": 17555,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 14611
        }
      ],
      "dockerImageVersionId": 30683,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "ðŸŒŸðŸš€Hexathlon IMC{:DinoV2:}ðŸš€ðŸŒŸ",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ktichola/Image-matching/blob/main/%F0%9F%8C%9F%F0%9F%9A%80Hexathlon_IMC%7B_DinoV2_%7D%F0%9F%9A%80%F0%9F%8C%9F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'image-matching-challenge-2024:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F71885%2F8143495%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240514%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240514T112612Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D59f7f3eaf4da62c477575a3a352f0c5f5ae59817aebfa62345b2c79888b57a572abde5452ea710174fc9c0d06deaf1efc4ac5f89bb2f1c31b509d16a0ea5580493dd11ad70191ca10fd02dbe4e68f733dcc522c8c04be3151462e08af2d2368f9778be75afc69e07eff2158425a324be54798637a2598801cda6bf9228e3c5f85dce4bd5c9d01c770b964bb77e1b36655ff5127607f00b24d9b1d62ccdf25f10e0bba7bcdd46e1c0226fea3330ba8c04d4d5aabf215139343c17b4b48af72c6cb0d9a3dc44a8ab0fee738d079950ab2e9924fd41dea41fd096b8e574691fcbf0b1b1e777bdffefb6b30b1af81c62498e42cd7f17d2e605e6c3b10e9507286dec,imc2024-packages-lightglue-rerun-kornia:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4628051%2F7884485%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240514%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240514T112612Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D57111324cb3ca7f9b3e96275fe36912b1288a300af2db325cf765084b9465eb61af2dca2aabf0aaa7f205844017488a0a6c33e1a25736ae5ea8e1453ed7fbe109f52f32c43507f90eaff6e57b03ed34dd841d0777d485d8043ffc362f8bfd189221840e6461cf66c00ce6cc9e41d7b852f4eb61b027801f8089ded69596d6af4340704b34f6b8c2f644af842a15b93dd1606ece36020f475c430625baf0001b957e4e6f7aaabb85a58c980ec5882585413c966c9f5b1e1e6eba93ee5abbae5c53f1778de20760f5cbd2b232a7b5f806cca73834b8873f82369de6438d09941de6f8838f15213535f28b08035849f698e275e94ca7f460092d67596d1d316a18c,colmap-db-import:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4628331%2F7884725%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240514%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240514T112612Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D41b8bd7ebca920eec37bffa54b751c0d7ae410241c96c310af565b49f9bc735237c6dece67a04eaeece3e312c5ffb72a6df70e8f819c304721dc386674ddfc073d18f43e9f131895b782b25a6eefcd49ad7e16cd143202c7614ebe04aca77857a858513b2ea6136f50667cd743315fb9ebfb15cf94dd19a289a48fd57d4014d8b5f3a6410c6673aac51e00fa275563dba173b503e9b805eaf4637442ef66d7beecd948c084ccb0ed5b0d6e2f4ea472c546ebc5b12064acb72b0ddd05368c51f432964931ed19542080b1bf8d00fd51a84e88ee0d1047f6c71f03656346adfd29845f182caebe452691813d20606438240da2e6cd4b50e468fff2dbfd527ba797,dinov2/pytorch/base/1:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-models-data%2F3326%2F4534%2Fbundle%2Farchive.tar.gz%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240514%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240514T112612Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D61d34a9ded914084edadf06831a58a71645a6f1b82d3cdf481e0d4c7ea5788b574cb6060d095c70788771d98e822714886a7c2239055d0062efb6617a57391d76c4700cfdd649af9aa8ae5b7aa42749b458e89795f10d208f9dc0ae0b46b200dad222799611fd0b42b7c4c76582dfe7b9777c8827e1f39b73406988e272ed561b482e34a82299e9bdb9782b046cd23c23e985cf354a64257aedc62bc1eaeeaf54b588aaf816d13bc372a79de64dc1a1fb83bb864d961e6a00096476dfc46147f182939c9a2052e37176013d738fd3a5c6b5f4bfb0fb29ce12ebae78b37377f66a10236338b04342d84f24511e2098332d98782a9b748dc3c2b0be18c29457cd1,lightglue/pytorch/aliked/1:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-models-data%2F14317%2F17191%2Fbundle%2Farchive.tar.gz%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240514%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240514T112612Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D55a7421bcdc4f1bbdc1cfb32d85dec49ecc1f24ee391e7f26e66c9f8d0495228e36c4a7ef9dc287b72a7aa08cbbf7bfc0eeebf822a8a6f3f8f398fc087b7b07e64d6afecf0ffae887b4f4058079811ae10455c51956efa5ed09980c3f90ee58d0c6adf00929ebacd95b034844b902ac0a81a4d2e327a00765c1b77c9832466aaa0a643748a458e7f2d499073c542ffb1c6d85def07953d4294a05714b1128390e7d42b8233bfd3982d51f3bc8d49b17509a2181f7a290a882da1e224360090342703539943fbbd74489996ce078bcd931279449682af292e731321b431bfd28cdc3dbd9eef6966ff9cdb9b29f008901d0b41624d0287b26c42c423b20e698299,aliked/pytorch/aliked-n16/1:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-models-data%2F14611%2F17555%2Fbundle%2Farchive.tar.gz%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240514%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240514T112612Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D7bf6a75e2ac1f57af27bf367259dc2f9c312815c0fd2b640330d1e5ee388944ca703e8ce056893a9ae760bc7d74ca7e1d8d2e01f8b220855bc9eeca364828662d515f30df1726973e696d7319f1bc2e7c283e5d0c245ed7130fe9646bfc11b58d7056720dab7bb2f5f7b52262a2afffd407759f65b984045c3ddd3d6974ca3bb822c1683e70f6b3edb476e2aad4c4da9be025a37acca39f64fbea8ea17fb722eeb7f3b35572fea48a9153d092e41d3a478b56c116cbc0999decf5d54c64458dffa4454201d6a98dd6909713a2f6c6a39f0f036b974ec5fa77d7d8476a26cc52abee8090f4dd59f1f0186eadafc98fd45908d040af366e2dd1f1c3bb2a87e9bee'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "qOVsiAZw2l12"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install userfull library:**"
      ],
      "metadata": {
        "id": "wwyFk9PZ2l14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --no-index /kaggle/input/imc2024-packages-lightglue-rerun-kornia/* --no-deps\n",
        "!mkdir -p /root/.cache/torch/hub/checkpoints\n",
        "!cp /kaggle/input/aliked/pytorch/aliked-n16/1/* /root/.cache/torch/hub/checkpoints/\n",
        "!cp /kaggle/input/lightglue/pytorch/aliked/1/* /root/.cache/torch/hub/checkpoints/\n",
        "!cp /kaggle/input/lightglue/pytorch/aliked/1/aliked_lightglue.pth /root/.cache/torch/hub/checkpoints/aliked_lightglue_v0-1_arxiv-pth"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-14T11:18:42.580442Z",
          "iopub.execute_input": "2024-05-14T11:18:42.580751Z",
          "iopub.status.idle": "2024-05-14T11:18:50.712385Z",
          "shell.execute_reply.started": "2024-05-14T11:18:42.580726Z",
          "shell.execute_reply": "2024-05-14T11:18:50.711139Z"
        },
        "trusted": true,
        "id": "aFFuoDjH2l15",
        "outputId": "0c001c78-268f-4b4a-d8d9-f19310f701af"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Processing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/kornia-0.7.2-py2.py3-none-any.whl\nProcessing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/kornia_moons-0.2.9-py3-none-any.whl\nProcessing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/kornia_rs-0.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nProcessing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/lightglue-0.0-py3-none-any.whl\nProcessing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/pycolmap-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nProcessing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/rerun_sdk-0.15.0a2-cp38-abi3-manylinux_2_31_x86_64.whl\nkornia is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\nInstalling collected packages: rerun-sdk, pycolmap, lightglue, kornia-rs, kornia-moons\n  Attempting uninstall: kornia-rs\n    Found existing installation: kornia_rs 0.1.3\n    Uninstalling kornia_rs-0.1.3:\n      Successfully uninstalled kornia_rs-0.1.3\nSuccessfully installed kornia-moons-0.2.9 kornia-rs-0.1.2 lightglue-0.0 pycolmap-0.6.1 rerun-sdk-0.15.0a2\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "from time import time, sleep\n",
        "from fastprogress import progress_bar\n",
        "import numpy as np\n",
        "import h5py\n",
        "from IPython.display import clear_output\n",
        "from collections import defaultdict\n",
        "from copy import deepcopy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from time import time, sleep\n",
        "from fastprogress import progress_bar\n",
        "import gc\n",
        "import numpy as np\n",
        "import h5py\n",
        "from IPython.display import clear_output\n",
        "from collections import defaultdict\n",
        "from copy import deepcopy\n",
        "from typing import Any\n",
        "import itertools\n",
        "import pandas as pd\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import kornia as K\n",
        "import kornia.feature as KF\n",
        "from PIL import Image\n",
        "from transformers import AutoImageProcessor, AutoModel\n",
        "\n",
        "import pycolmap\n",
        "\n",
        "import sys\n",
        "sys.path.append('/kaggle/input/colmap-db-import')\n",
        "from database import *\n",
        "from h5_to_db import *\n",
        "\n",
        "def arr_to_str(a):\n",
        "    return ';'.join([str(x) for x in a.reshape(-1)])\n",
        "\n",
        "def load_torch_image(fname, device=torch.device('cpu')):\n",
        "    img = K.io.load_image(fname, K.io.ImageLoadType.RGB32, device=device)[None, ...]\n",
        "    return img\n",
        "\n",
        "device = K.utils.get_cuda_device_if_available(0)\n",
        "print (device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-14T11:18:50.71483Z",
          "iopub.execute_input": "2024-05-14T11:18:50.715601Z",
          "iopub.status.idle": "2024-05-14T11:19:09.676987Z",
          "shell.execute_reply.started": "2024-05-14T11:18:50.715544Z",
          "shell.execute_reply": "2024-05-14T11:19:09.676055Z"
        },
        "trusted": true,
        "id": "uHT4LAKb2l16",
        "outputId": "65fe38d0-4bbc-4fd5-f9e7-775303b5433a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "2024-05-14 11:19:01.173890: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-14 11:19:01.173993: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-14 11:19:01.316880: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "cuda:0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building image pairs**"
      ],
      "metadata": {
        "id": "fxYdls7J2l16"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](attachment:ce6378f6-e22b-41ef-9749-0e2c453dd753.png)"
      ],
      "metadata": {
        "id": "StNzRGiM2l17"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "<meta charset=\"UTF-8\">\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "<title>Description of Code Functionality</title>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<h1>Description of Code Functionality</h1>\n",
        "\n",
        "<h2>Function: get_global_desc</h2>\n",
        "<p>The <code>get_global_desc</code> function extracts global descriptors from a set of images using a DINOv2 model. It preprocesses the images, passes them through the DINOv2 model, and extracts the global descriptors from the model's output. These descriptors are then normalized and returned.</p>\n",
        "\n",
        "<h2>Function: get_img_pairs_exhaustive</h2>\n",
        "<p>The <code>get_img_pairs_exhaustive</code> function generates all possible pairs of images from a list of image filenames. It iterates over all combinations of image indices, ensuring that each pair is unique.</p>\n",
        "\n",
        "<h2>Function: get_image_pairs_shortlist</h2>\n",
        "<p>The <code>get_image_pairs_shortlist</code> function generates pairs of images based on the similarity of their global descriptors. It calculates the pairwise distances between global descriptors, thresholding them based on a similarity threshold. If the number of images is below a certain threshold, it performs an exhaustive search for all possible pairs. Otherwise, it shortlists pairs based on similarity, ensuring a minimum number of pairs.</p>\n",
        "\n",
        "<p>This code provides functions for generating pairs of images either exhaustively or based on global descriptor similarity, enabling downstream tasks such as image matching and registration.</p>\n",
        "\n",
        "</body>\n",
        "</html>\n"
      ],
      "metadata": {
        "id": "aX1inAAe2l17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_global_desc(fnames, device = torch.device('cpu')):\n",
        "    processor = AutoImageProcessor.from_pretrained('/kaggle/input/dinov2/pytorch/base/1')\n",
        "    model = AutoModel.from_pretrained('/kaggle/input/dinov2/pytorch/base/1')\n",
        "    model = model.eval()\n",
        "    model = model.to(device)\n",
        "    global_descs_dinov2 = []\n",
        "    for i, img_fname_full in tqdm(enumerate(fnames),total= len(fnames)):\n",
        "        key = os.path.splitext(os.path.basename(img_fname_full))[0]\n",
        "        timg = load_torch_image(img_fname_full)\n",
        "        with torch.inference_mode():\n",
        "            inputs = processor(images=timg, return_tensors=\"pt\", do_rescale=False).to(device)\n",
        "            outputs = model(**inputs)\n",
        "            dino_mac = F.normalize(outputs.last_hidden_state[:,1:].max(dim=1)[0], dim=1, p=2)\n",
        "        global_descs_dinov2.append(dino_mac.detach().cpu())\n",
        "    global_descs_dinov2 = torch.cat(global_descs_dinov2, dim=0)\n",
        "    return global_descs_dinov2\n",
        "\n",
        "def get_img_pairs_exhaustive(img_fnames):\n",
        "    index_pairs = []\n",
        "    for i in range(len(img_fnames)):\n",
        "        for j in range(i+1, len(img_fnames)):\n",
        "            index_pairs.append((i,j))\n",
        "    return index_pairs\n",
        "\n",
        "def get_image_pairs_shortlist(fnames,\n",
        "                              sim_th = 0.6,\n",
        "                              min_pairs = 20,\n",
        "                              exhaustive_if_less = 20,\n",
        "                              device=torch.device('cpu')):\n",
        "    num_imgs = len(fnames)\n",
        "    if num_imgs <= exhaustive_if_less:\n",
        "        return get_img_pairs_exhaustive(fnames)\n",
        "    descs = get_global_desc(fnames, device=device)\n",
        "    dm = torch.cdist(descs, descs, p=2).detach().cpu().numpy()\n",
        "    mask = dm <= sim_th\n",
        "    total = 0\n",
        "    matching_list = []\n",
        "    ar = np.arange(num_imgs)\n",
        "    already_there_set = []\n",
        "    for st_idx in range(num_imgs-1):\n",
        "        mask_idx = mask[st_idx]\n",
        "        to_match = ar[mask_idx]\n",
        "        if len(to_match) < min_pairs:\n",
        "            to_match = np.argsort(dm[st_idx])[:min_pairs]\n",
        "        for idx in to_match:\n",
        "            if st_idx == idx:\n",
        "                continue\n",
        "            if dm[st_idx, idx] < 1000:\n",
        "                matching_list.append(tuple(sorted((st_idx, idx.item()))))\n",
        "                total+=1\n",
        "    matching_list = sorted(list(set(matching_list)))\n",
        "    return matching_list"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-14T11:19:09.678231Z",
          "iopub.execute_input": "2024-05-14T11:19:09.678791Z",
          "iopub.status.idle": "2024-05-14T11:19:09.697771Z",
          "shell.execute_reply.started": "2024-05-14T11:19:09.678764Z",
          "shell.execute_reply": "2024-05-14T11:19:09.692464Z"
        },
        "trusted": true,
        "id": "woq7Fz3R2l17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Self-supervised Keypoint Learning â€” A Review**"
      ],
      "metadata": {
        "id": "ymr5kQ9e2l17"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "<meta charset=\"UTF-8\">\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "<title>Keypoint Detection in Computer Vision</title>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<h1>Keypoint Detection in Computer Vision</h1>\n",
        "\n",
        "<p>Keypoint or interest point detection is one important building block for many computer vision tasks, such as SLAM (simultaneous localization and mapping), SfM (structure from motion), and camera calibration. Keypoint detection has a long history predating deep learning, and many glorious algorithms in wide industry applications (such as FAST, SIFT, and ORB) are based on hand-crafted features. As in many other computer vision tasks, people have been exploring how to use deep learning to outperform hand-crafted algorithms. In this post, we will review some recent advances in this field.</p>\n",
        "\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "id": "jE3cOgXh2l18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](attachment:8b1e36db-6628-4ad8-a031-67b52890f59b.png)"
      ],
      "metadata": {
        "id": "_7AwJFG32l18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "<meta charset=\"UTF-8\">\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "<title></title>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<h1>Description of Code Functionality</h1>\n",
        "\n",
        "<p>This code snippet demonstrates a series of functions for keypoint detection, feature matching, and importing data into COLMAP, a Structure-from-Motion (SfM) and Multi-View Stereo (MVS) pipeline.</p>\n",
        "\n",
        "<h2>Function: detect_aliked</h2>\n",
        "<p>The <code>detect_aliked</code> function is responsible for detecting keypoints and extracting descriptors from images using the ALIKED model. Key points and descriptors are then stored in HDF5 files for each image.</p>\n",
        "\n",
        "<h2>Function: match_with_lightglue</h2>\n",
        "<p>The <code>match_with_lightglue</code> function matches features between pairs of images using the LightGlueMatcher model. It loads keypoints and descriptors from HDF5 files, performs feature matching, and saves the matches to another HDF5 file.</p>\n",
        "\n",
        "<h2>Function: import_into_colmap</h2>\n",
        "<p>The <code>import_into_colmap</code> function imports keypoints and matches into a COLMAP database. It connects to the database, adds keypoints and matches to it, and commits the changes.</p>\n",
        "\n",
        "<p>This code serves as a pipeline for feature extraction, matching, and importing data into COLMAP for further 3D reconstruction and analysis.</p>\n",
        "\n",
        "</body>\n",
        "</html>\n"
      ],
      "metadata": {
        "id": "QXczYl1p2l18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from lightglue import match_pair\n",
        "from lightglue import ALIKED, LightGlue\n",
        "from lightglue.utils import load_image, rbd\n",
        "\n",
        "def detect_aliked(img_fnames,\n",
        "                  feature_dir = '.featureout',\n",
        "                  num_features = 4096,\n",
        "                  resize_to = 1024,\n",
        "                  device=torch.device('cpu')):\n",
        "    dtype = torch.float32\n",
        "    extractor = ALIKED(max_num_keypoints=num_features, detection_threshold=0.01, resize=resize_to).eval().to(device, dtype)\n",
        "    if not os.path.isdir(feature_dir):\n",
        "        os.makedirs(feature_dir)\n",
        "    with h5py.File(f'{feature_dir}/keypoints.h5', mode='w') as f_kp, \\\n",
        "         h5py.File(f'{feature_dir}/descriptors.h5', mode='w') as f_desc:\n",
        "        for img_path in tqdm(img_fnames):\n",
        "            img_fname = img_path.split('/')[-1]\n",
        "            key = img_fname\n",
        "            with torch.inference_mode():\n",
        "                image0 = load_torch_image(img_path, device=device).to(dtype)\n",
        "                feats0 = extractor.extract(image0)\n",
        "                kpts = feats0['keypoints'].reshape(-1, 2).detach().cpu().numpy()\n",
        "                descs = feats0['descriptors'].reshape(len(kpts), -1).detach().cpu().numpy()\n",
        "                f_kp[key] = kpts\n",
        "                f_desc[key] = descs\n",
        "    return\n",
        "\n",
        "def match_with_lightglue(img_fnames,\n",
        "                   index_pairs,\n",
        "                   feature_dir = '.featureout',\n",
        "                   device=torch.device('cpu'),\n",
        "                   min_matches=15,verbose=True):\n",
        "    lg_matcher = KF.LightGlueMatcher(\"aliked\", {\"width_confidence\": -1,\n",
        "                                                \"depth_confidence\": -1,\n",
        "                                                 \"mp\": True if 'cuda' in str(device) else False}).eval().to(device)\n",
        "    with h5py.File(f'{feature_dir}/keypoints.h5', mode='r') as f_kp, \\\n",
        "        h5py.File(f'{feature_dir}/descriptors.h5', mode='r') as f_desc, \\\n",
        "        h5py.File(f'{feature_dir}/matches.h5', mode='w') as f_match:\n",
        "        for pair_idx in tqdm(index_pairs):\n",
        "            idx1, idx2 = pair_idx\n",
        "            fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n",
        "            key1, key2 = fname1.split('/')[-1], fname2.split('/')[-1]\n",
        "            kp1 = torch.from_numpy(f_kp[key1][...]).to(device)\n",
        "            kp2 = torch.from_numpy(f_kp[key2][...]).to(device)\n",
        "            desc1 = torch.from_numpy(f_desc[key1][...]).to(device)\n",
        "            desc2 = torch.from_numpy(f_desc[key2][...]).to(device)\n",
        "            with torch.inference_mode():\n",
        "                dists, idxs = lg_matcher(desc1,\n",
        "                                         desc2,\n",
        "                                         KF.laf_from_center_scale_ori(kp1[None]),\n",
        "                                         KF.laf_from_center_scale_ori(kp2[None]))\n",
        "            if len(idxs)  == 0:\n",
        "                continue\n",
        "            n_matches = len(idxs)\n",
        "            if verbose:\n",
        "                print (f'{key1}-{key2}: {n_matches} matches')\n",
        "            group  = f_match.require_group(key1)\n",
        "            if n_matches >= min_matches:\n",
        "                 group.create_dataset(key2, data=idxs.detach().cpu().numpy().reshape(-1, 2))\n",
        "    return\n",
        "\n",
        "def import_into_colmap(img_dir,\n",
        "                       feature_dir ='.featureout',\n",
        "                       database_path = 'colmap.db'):\n",
        "    db = COLMAPDatabase.connect(database_path)\n",
        "    db.create_tables()\n",
        "    single_camera = False\n",
        "    fname_to_id = add_keypoints(db, feature_dir, img_dir, '', 'simple-pinhole', single_camera)\n",
        "    add_matches(\n",
        "        db,\n",
        "        feature_dir,\n",
        "        fname_to_id,\n",
        "    )\n",
        "    db.commit()\n",
        "    return"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-14T11:19:46.688872Z",
          "iopub.execute_input": "2024-05-14T11:19:46.689553Z",
          "iopub.status.idle": "2024-05-14T11:19:46.994483Z",
          "shell.execute_reply.started": "2024-05-14T11:19:46.689526Z",
          "shell.execute_reply": "2024-05-14T11:19:46.993511Z"
        },
        "trusted": true,
        "id": "ktrIyh1k2l18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src = '/kaggle/input/image-matching-challenge-2024/'\n",
        "\n",
        "data_dict = {}\n",
        "with open(f'{src}/sample_submission.csv', 'r') as f:\n",
        "    for i, l in enumerate(f):\n",
        "        if i== 0:\n",
        "            print (l)\n",
        "        if l and i > 0:\n",
        "            image_path, dataset, scene, _, _ = l.strip().split(',')\n",
        "            if dataset not in data_dict:\n",
        "                data_dict[dataset] = {}\n",
        "            if scene not in data_dict[dataset]:\n",
        "                data_dict[dataset][scene] = []\n",
        "            data_dict[dataset][scene].append(image_path)\n",
        "for dataset in data_dict:\n",
        "    for scene in data_dict[dataset]:\n",
        "        print(f'{dataset} / {scene} -> {len(data_dict[dataset][scene])} images')\n",
        "\n",
        "out_results = {}\n",
        "timings = {\"shortlisting\":[],\n",
        "           \"feature_detection\": [],\n",
        "           \"feature_matching\":[],\n",
        "           \"RANSAC\": [],\n",
        "           \"Reconstruction\": []}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-14T11:19:47.628872Z",
          "iopub.execute_input": "2024-05-14T11:19:47.629762Z",
          "iopub.status.idle": "2024-05-14T11:19:47.64121Z",
          "shell.execute_reply.started": "2024-05-14T11:19:47.629725Z",
          "shell.execute_reply": "2024-05-14T11:19:47.640295Z"
        },
        "trusted": true,
        "id": "X0byi-uB2l19",
        "outputId": "79e779d0-df0b-4468-f262-18be79783d27"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "image_path,dataset,scene,rotation_matrix,translation_vector\n\nchurch / church -> 41 images\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_submission(out_results, data_dict):\n",
        "    with open(f'submission.csv', 'w') as f:\n",
        "        f.write('image_path,dataset,scene,rotation_matrix,translation_vector\\n')\n",
        "        for dataset in data_dict:\n",
        "            if dataset in out_results:\n",
        "                res = out_results[dataset]\n",
        "            else:\n",
        "                res = {}\n",
        "            for scene in data_dict[dataset]:\n",
        "                if scene in res:\n",
        "                    scene_res = res[scene]\n",
        "                else:\n",
        "                    scene_res = {\"R\":{}, \"t\":{}}\n",
        "                for image in data_dict[dataset][scene]:\n",
        "                    if image in scene_res:\n",
        "                        print (image)\n",
        "                        R = scene_res[image]['R'].reshape(-1)\n",
        "                        T = scene_res[image]['t'].reshape(-1)\n",
        "                    else:\n",
        "                        R = np.eye(3).reshape(-1)\n",
        "                        T = np.zeros((3))\n",
        "                    f.write(f'{image},{dataset},{scene},{arr_to_str(R)},{arr_to_str(T)}\\n')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-14T11:19:48.993214Z",
          "iopub.execute_input": "2024-05-14T11:19:48.993565Z",
          "iopub.status.idle": "2024-05-14T11:19:49.002187Z",
          "shell.execute_reply.started": "2024-05-14T11:19:48.993532Z",
          "shell.execute_reply": "2024-05-14T11:19:49.001248Z"
        },
        "trusted": true,
        "id": "Fwmib7nO2l19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "<meta charset=\"UTF-8\">\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<h1>Description of Code Functionality</h1>\n",
        "\n",
        "<h2>Initialization and Data Preparation</h2>\n",
        "<p>The code initializes variables and prepares the data for processing.</p>\n",
        "\n",
        "<h2>Feature Extraction and Matching</h2>\n",
        "<p>The code iterates over datasets and scenes, extracting features from images, shortlisting image pairs based on similarity, detecting keypoints and descriptors, matching features, and importing data into COLMAP for further processing.</p>\n",
        "\n",
        "<h2>3D Reconstruction and Registration</h2>\n",
        "<p>The code performs 3D reconstruction and registration tasks, including RANSAC matching, incremental mapping, selecting the best reconstruction, extracting rotation and translation matrices, and creating submission files.</p>\n",
        "\n",
        "<h2>Error Handling</h2>\n",
        "<p>Exception handling is implemented to catch any errors that may occur during the processing of datasets and scenes.</p>\n",
        "\n",
        "<p>This code segment automates the process of feature extraction, matching, 3D reconstruction, and registration for multiple datasets and scenes, providing efficient data processing and feedback on the progress of each step.</p>\n",
        "\n",
        "</body>\n",
        "</html>\n"
      ],
      "metadata": {
        "id": "ZPin-r5P2l19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()\n",
        "from copy import deepcopy\n",
        "datasets = []\n",
        "for dataset in data_dict:\n",
        "    datasets.append(dataset)\n",
        "print (f\"Extracting on device {device}\")\n",
        "for dataset in data_dict:\n",
        "    print(dataset)\n",
        "    if dataset not in out_results:\n",
        "        out_results[dataset] = {}\n",
        "    for scene in data_dict[dataset]:\n",
        "        print(scene)\n",
        "        img_dir =  os.path.join(src,  '/'.join(data_dict[dataset][scene][0].split('/')[:-1]))\n",
        "        try:\n",
        "            out_results[dataset][scene] = {}\n",
        "            img_fnames = [os.path.join(src, x) for x in data_dict[dataset][scene] ]\n",
        "            print (f\"Got {len(img_fnames)} images\")\n",
        "            feature_dir = f'featureout/{dataset}_{scene}'\n",
        "            os.makedirs(feature_dir, exist_ok=True)\n",
        "            t=time()\n",
        "            index_pairs = get_image_pairs_shortlist(img_fnames,\n",
        "                                  sim_th = 0.3,\n",
        "                                  min_pairs = 20,\n",
        "                                  exhaustive_if_less = 20,\n",
        "                                  device=device)\n",
        "            t=time() -t\n",
        "            timings['shortlisting'].append(t)\n",
        "            print (f'{len(index_pairs)}, pairs to match, {t:.4f} sec')\n",
        "            gc.collect()\n",
        "            t=time()\n",
        "            detect_aliked(img_fnames, feature_dir, 4096, device=device)\n",
        "            gc.collect()\n",
        "            t=time() -t\n",
        "            timings['feature_detection'].append(t)\n",
        "            print(f'Features detected in  {t:.4f} sec')\n",
        "            t=time()\n",
        "            match_with_lightglue(img_fnames, index_pairs, feature_dir=feature_dir,device=device)\n",
        "            t=time() -t\n",
        "            timings['feature_matching'].append(t)\n",
        "            print(f'Features matched in  {t:.4f} sec')\n",
        "            database_path = f'{feature_dir}/colmap.db'\n",
        "            if os.path.isfile(database_path):\n",
        "                os.remove(database_path)\n",
        "            gc.collect()\n",
        "            sleep(1)\n",
        "            import_into_colmap(img_dir, feature_dir=feature_dir, database_path=database_path)\n",
        "            output_path = f'{feature_dir}/colmap_rec_aliked'\n",
        "            t=time()\n",
        "            pycolmap.match_exhaustive(database_path)\n",
        "            t=time() - t\n",
        "            timings['RANSAC'].append(t)\n",
        "            print(f'RANSAC in  {t:.4f} sec')\n",
        "            t=time()\n",
        "            mapper_options = pycolmap.IncrementalPipelineOptions()\n",
        "            mapper_options.min_model_size = 3\n",
        "            mapper_options.max_num_models = 2\n",
        "            os.makedirs(output_path, exist_ok=True)\n",
        "            maps = pycolmap.incremental_mapping(database_path=database_path,\n",
        "                                                image_path=img_dir,\n",
        "                                                output_path=output_path, options=mapper_options)\n",
        "            sleep(1)\n",
        "            print(maps)\n",
        "            clear_output(wait=False)\n",
        "            t=time() - t\n",
        "            timings['Reconstruction'].append(t)\n",
        "            print(f'Reconstruction done in  {t:.4f} sec')\n",
        "            imgs_registered  = 0\n",
        "            best_idx = None\n",
        "            print (\"Looking for the best reconstruction\")\n",
        "            if isinstance(maps, dict):\n",
        "                for idx1, rec in maps.items():\n",
        "                    print (idx1, rec.summary())\n",
        "                    try:\n",
        "                        if len(rec.images) > imgs_registered:\n",
        "                            imgs_registered = len(rec.images)\n",
        "                            best_idx = idx1\n",
        "                    except:\n",
        "                        continue\n",
        "            if best_idx is not None:\n",
        "                print (maps[best_idx].summary())\n",
        "                for k, im in maps[best_idx].images.items():\n",
        "                    key1 = f'test/{scene}/images/{im.name}'\n",
        "                    print(key1)\n",
        "                    out_results[dataset][scene][key1] = {}\n",
        "                    out_results[dataset][scene][key1][\"R\"] = deepcopy(im.cam_from_world.rotation.matrix())\n",
        "                    out_results[dataset][scene][key1][\"t\"] = deepcopy(np.array(im.cam_from_world.translation))\n",
        "            print(f'Registered: {dataset} / {scene} -> {len(out_results[dataset][scene])} images')\n",
        "            print(f'Total: {dataset} / {scene} -> {len(data_dict[dataset][scene])} images')\n",
        "            create_submission(out_results, data_dict)\n",
        "            gc.collect()\n",
        "        except Exception as e:\n",
        "            print (e)\n",
        "            pass"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-14T11:19:52.890023Z",
          "iopub.execute_input": "2024-05-14T11:19:52.8904Z",
          "iopub.status.idle": "2024-05-14T11:25:27.013082Z",
          "shell.execute_reply.started": "2024-05-14T11:19:52.890371Z",
          "shell.execute_reply": "2024-05-14T11:25:27.012206Z"
        },
        "trusted": true,
        "id": "fHL3cLTa2l19",
        "outputId": "27343b9b-5f58-4ec5-a8a0-12236428ef05"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Reconstruction done in  154.6709 sec\nLooking for the best reconstruction\n0 Reconstruction:\n\tnum_reg_images = 39\n\tnum_cameras = 39\n\tnum_points3D = 12288\n\tnum_observations = 64013\n\tmean_track_length = 5.20939\n\tmean_observations_per_image = 1641.36\n\tmean_reprojection_error = 0.9047\nReconstruction:\n\tnum_reg_images = 39\n\tnum_cameras = 39\n\tnum_points3D = 12288\n\tnum_observations = 64013\n\tmean_track_length = 5.20939\n\tmean_observations_per_image = 1641.36\n\tmean_reprojection_error = 0.9047\ntest/church/images/00001.png\ntest/church/images/00006.png\ntest/church/images/00008.png\ntest/church/images/00010.png\ntest/church/images/00011.png\ntest/church/images/00012.png\ntest/church/images/00013.png\ntest/church/images/00018.png\ntest/church/images/00021.png\ntest/church/images/00024.png\ntest/church/images/00026.png\ntest/church/images/00029.png\ntest/church/images/00030.png\ntest/church/images/00032.png\ntest/church/images/00035.png\ntest/church/images/00037.png\ntest/church/images/00039.png\ntest/church/images/00042.png\ntest/church/images/00046.png\ntest/church/images/00050.png\ntest/church/images/00058.png\ntest/church/images/00059.png\ntest/church/images/00060.png\ntest/church/images/00061.png\ntest/church/images/00063.png\ntest/church/images/00066.png\ntest/church/images/00068.png\ntest/church/images/00069.png\ntest/church/images/00072.png\ntest/church/images/00074.png\ntest/church/images/00076.png\ntest/church/images/00081.png\ntest/church/images/00083.png\ntest/church/images/00087.png\ntest/church/images/00090.png\ntest/church/images/00092.png\ntest/church/images/00096.png\ntest/church/images/00102.png\ntest/church/images/00111.png\nRegistered: church / church -> 39 images\nTotal: church / church -> 41 images\ntest/church/images/00046.png\ntest/church/images/00090.png\ntest/church/images/00092.png\ntest/church/images/00087.png\ntest/church/images/00050.png\ntest/church/images/00068.png\ntest/church/images/00083.png\ntest/church/images/00096.png\ntest/church/images/00069.png\ntest/church/images/00081.png\ntest/church/images/00042.png\ntest/church/images/00018.png\ntest/church/images/00030.png\ntest/church/images/00024.png\ntest/church/images/00032.png\ntest/church/images/00026.png\ntest/church/images/00037.png\ntest/church/images/00008.png\ntest/church/images/00035.png\ntest/church/images/00021.png\ntest/church/images/00010.png\ntest/church/images/00039.png\ntest/church/images/00011.png\ntest/church/images/00013.png\ntest/church/images/00006.png\ntest/church/images/00012.png\ntest/church/images/00029.png\ntest/church/images/00001.png\ntest/church/images/00072.png\ntest/church/images/00066.png\ntest/church/images/00058.png\ntest/church/images/00059.png\ntest/church/images/00111.png\ntest/church/images/00061.png\ntest/church/images/00060.png\ntest/church/images/00074.png\ntest/church/images/00102.png\ntest/church/images/00076.png\ntest/church/images/00063.png\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat submission.csv"
      ],
      "metadata": {
        "trusted": true,
        "id": "XK2B4fe72l1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Submission = pd.read_csv('submission.csv')\n",
        "\n",
        "print(Submission)"
      ],
      "metadata": {
        "trusted": true,
        "id": "A4lqrtP62l1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Submission.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "lSWqnx8u2l2A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}